
@video{AIRedactionDemo,
  title = {{{AI Redaction Demo}}},
  url = {https://www.youtube.com/watch?v=gRXV-q_5Fxs},
  urldate = {2020-03-26},
  abstract = {An introduction to the business case and demo of the solution using Microsoft Applied AI to scan documents for Credit Card numbers and redact them. This example could help organizations meet Payment card industry (PCI) compliance.}
}
% == BibLateX quality report for AIRedactionDemo:
% Unexpected field 'title'
% ? Title looks like it was stored in title-case in Zotero

@report{allanRecordsReview2014,
  title = {Records {{Review}}},
  author = {Allan, Alex},
  date = {2014-08},
  pages = {39},
  institution = {{Cabinet Office}},
  url = {https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/370930/RECORDS_REVIEW_-_Sir_Allex_Allan.pdf},
  urldate = {2020-03-26},
  abstract = {I was asked by the Cabinet Secretary on 18 March to carry out a review to establish the position across Government on the annual release of papers;the ability and readiness of departments to meet the requirements of moving from a 30 to a 20 year rule; andthe processes for withholding information where releasewould harm individuals or the national interest.My full terms of reference are attachedas Annex 1.},
  file = {/home/architect/Zotero/storage/93XUTHQL/RECORDS_REVIEW_-_Sir_Allex_Allan.pdf},
  langid = {english}
}
% == BibLateX quality report for allanRecordsReview2014:
% Missing required field 'type'
% ? Title looks like it was stored in title-case in Zotero

@article{alzhraniAutomatedBigText2016,
  title = {Automated {{Big Text Security Classification}}},
  author = {Alzhrani, Khudran and Rudd, Ethan M. and Boult, Terrance E. and Chow, C. Edward},
  date = {2016-10-21},
  url = {http://arxiv.org/abs/1610.06856},
  urldate = {2019-10-07},
  abstract = {In recent years, traditional cybersecurity safeguards have proven ineffective against insider threats. Famous cases of sensitive information leaks caused by insiders, including the WikiLeaks release of diplomatic cables and the Edward Snowden incident, have greatly harmed the U.S. government's relationship with other governments and with its own citizens. Data Leak Prevention (DLP) is a solution for detecting and preventing information leaks from within an organization's network. However, state-of-art DLP detection models are only able to detect very limited types of sensitive information, and research in the field has been hindered due to the lack of available sensitive texts. Many researchers have focused on document-based detection with artificially labeled ``confidential documents'' for which security labels are assigned to the entire document, when in reality only a portion of the document is sensitive. This type of whole-document based security labeling increases the chances of preventing authorized users from accessing non-sensitive information within sensitive documents. In this paper, we introduce Automated Classification Enabled by Security Similarity (ACESS), a new and innovative detection model that penetrates the complexity of big text security classification/detection. To analyze the ACESS system, we constructed a novel dataset, containing formerly classified paragraphs from diplomatic cables made public by the WikiLeaks organization. To our knowledge this paper is the first to analyze a dataset that contains actual formerly sensitive information annotated at paragraph granularity.},
  archivePrefix = {arXiv},
  eprint = {1610.06856},
  eprinttype = {arxiv},
  file = {/home/architect/Zotero/storage/RVEDGCXL/Alzhrani et al. - 2016 - Automated Big Text Security Classification.pdf},
  keywords = {â›” No DOI found,Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computers and Society,Computer Science - Cryptography and Security,No DOI found},
  langid = {english},
  primaryClass = {cs}
}
% == BibLateX quality report for alzhraniAutomatedBigText2016:
% Unexpected field 'archivePrefix'
% Unexpected field 'primaryClass'
% Missing required field 'journaltitle'
% ? Title looks like it was stored in title-case in Zotero

@software{Angular2020,
  title = {Angular},
  date = {2020},
  origdate = {2014-09-18T16:12:01Z},
  url = {https://github.com/angular/angular},
  urldate = {2020-03-20},
  abstract = {One framework. Mobile \& desktop. Contribute to angular/angular development by creating an account on GitHub.},
  keywords = {angular,javascript,pwa,typescript,web,web-framework,web-performance},
  organization = {{Angular}}
}
% == BibLateX quality report for Angular2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@incollection{apperleyBifocalDisplay,
  title = {Bifocal {{Display}}},
  booktitle = {The {{Encyclopedia}} of {{Human}}-{{Computer Interaction}}},
  author = {Apperley, Mark and Spence, Robert},
  date = {2013},
  edition = {2nd edition},
  publisher = {{The Interaction Design Foundation}},
  url = {https://www.interaction-design.org/literature/book/the-encyclopedia-of-human-computer-interaction-2nd-ed/bifocal-display},
  urldate = {2019-12-10},
  abstract = {Ever wondered who invented the visualization technique behind the Apple Dock - used by millions of people every day? Bob Spence and Mark Apperley explain their invention of the Bifocal Display},
  file = {/home/architect/Zotero/storage/D6RP24GG/bifocal-display.html},
  isbn = {9788792964},
  langid = {english}
}
% == BibLateX quality report for apperleyBifocalDisplay:
% Missing required field 'editor'
% 'isbn': not a valid ISBN
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{baeza-yatesVisualizationLargeAnswers1996,
  title = {Visualization of {{Large Answers}} in {{Text Databases}}},
  booktitle = {Proceedings of the {{Workshop}} on {{Advanced Visual Interfaces}}},
  author = {Baeza-Yates, Ricardo},
  date = {1996},
  pages = {101--107},
  publisher = {{ACM}},
  location = {{Gubbio, Italy}},
  doi = {10.1145/948449.948464},
  abstract = {Current user interfaces of full text retrieval systems do not help in the process of filtering the result of a query, usually very large. We address this problem and we propose a visual interface to handle the result of a query, based on a hybrid model for text. This graphical user interface provides several visual representations of the answer and its elements (queries, documents, and text), easing the analysis and the filtering process.},
  file = {/home/architect/Zotero/storage/KNNZRVHX/Baeza-Yates - 1996 - Visualization of Large Answers in Text Databases.pdf;/home/architect/Zotero/storage/AP9L3KP2/baeza-yates1996.html},
  isbn = {978-0-89791-834-3},
  keywords = {set visualization,visual analysis,visual browsing,visual query languages,visual representations,visual text database,visual tools},
  series = {{{AVI}} '96}
}
% == BibLateX quality report for baeza-yatesVisualizationLargeAnswers1996:
% ? Title looks like it was stored in title-case in Zotero

@article{ballUnredactedUSEmbassy2011,
  title = {Unredacted {{US}} Embassy Cables Available Online after {{WikiLeaks}} Breach},
  author = {Ball, James},
  date = {2011-09-01T00:00:07.000Z},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/world/2011/sep/01/unredacted-us-embassy-cables-online},
  urldate = {2019-12-19},
  abstract = {Guardian denies allegation in WikiLeaks statement that journalist disclosed passwords to archive},
  entrysubtype = {newspaper},
  file = {/home/architect/Zotero/storage/XENY5EIG/unredacted-us-embassy-cables-online.html},
  journalsubtitle = {US news},
  keywords = {Media,The US embassy cables,US foreign policy,US national security,US news,WikiLeaks,World news},
  langid = {british}
}

@article{barryManMachineReview2012,
  title = {Man versus {{Machine Review}}: {{The Showdown}} between {{Hordes}} of {{Discovery Lawyers}} and a {{Computer}}-{{Utilizing Predictive}}-{{Coding Technology Note}}},
  shorttitle = {Man versus {{Machine Review}}},
  author = {Barry, Nicholas},
  date = {2012/2013},
  journaltitle = {Vanderbilt Journal of Entertainment and Technology Law},
  shortjournal = {Vand. J. Ent. \& Tech. L.},
  volume = {15},
  pages = {343--374},
  url = {https://heinonline.org/HOL/P?h=hein.journals/vanep15&i=359},
  urldate = {2020-03-15},
  file = {/home/architect/Zotero/storage/ZECQYAUS/Barry - 2012 - Man versus Machine Review The Showdown between Ho.pdf},
  langid = {english},
  number = {2}
}
% == BibLateX quality report for barryManMachineReview2012:
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{bartramContinuousZoomConstrained1995,
  title = {The Continuous Zoom: A Constrained Fisheye Technique for Viewing and Navigating Large Information Spaces},
  shorttitle = {The Continuous Zoom},
  booktitle = {Proceedings of the 8th Annual {{ACM}} Symposium on {{User}} Interface and Software Technology  - {{UIST}} '95},
  author = {Bartram, Lyn and Ho, Albert and Dill, John and Henigman, Frank},
  date = {1995},
  pages = {207--215},
  publisher = {{ACM Press}},
  location = {{Pittsburgh, Pennsylvania, United States}},
  doi = {10.1145/215585.215977},
  abstract = {Navigating and viewing large information spaces, such as hierarchically-organized networks from complex realtime systems, suffer the problems of viewing a large space on a small screen. Distorted-view approaches, such as fisheye techniques, have great potential to reduce these problems by representing detail within its larger context but introduce new issues of focus, transition between views and user disorientation from excessive distortion. We present a fisheyebased method which supports multiple focus points, enhances continuity through smooth transitions between views, and maintains location constraints to reduce the user's sense of spatial disorientation. These are important requirements for the representation and navigation of networked systems in supervisory control applications. The method consists of two steps: a global allocation of space to rectangular sections of the display, based on scale factors, followed by degree-of-interest adjustments. Previous versions of the algorithm relied solely on relative scale factors to assign size; we present a new version which allocates space more efficiently using a dynamically calculated degree of interest. In addition to the automatic system sizing, manual user control over the amount of space assigned each area is supported. The amount of detail shown in various parts of the network is controlled by pruning the hierarchy and presenting those sections in summary form.},
  eventtitle = {The 8th Annual {{ACM}} Symposium},
  file = {/home/architect/Zotero/storage/L4VTTZGJ/Bartram et al. - 1995 - The continuous zoom a constrained fisheye techniq.pdf;/home/architect/Zotero/storage/F36BLJXL/bartram1995.html},
  isbn = {978-0-89791-709-4},
  langid = {english}
}
% == BibLateX quality report for bartramContinuousZoomConstrained1995:
% ? Unsure about the formatting of the booktitle

@misc{batistaStudyBehaviorSeveral2004,
  title = {A Study of the Behavior of Several Methods for Balancing Machine Learning Training Data},
  author = {Batista, Gustavo E. A. P. A. and Prati, Ronaldo C. and Monard, Maria Carolina},
  date = {2004-06-01},
  publisher = {{Association for Computing Machinery}},
  url = {http://doi.org/10.1145/1007730.1007735},
  urldate = {2020-03-27},
  abstract = {There are several aspects that might influence the performance achieved by existing learning systems. It has been reported that one of these aspects is related to class imbalance in which examples in training data belonging to one class heavily outnumber the examples in the other class. In this situation, which is found in real world data describing an infrequent but important event, the learning system may have difficulties to learn the concept related to the minority class. In this work we perform a broad experimental evaluation involving ten methods, three of them proposed by the authors, to deal with the class imbalance problem in thirteen UCI data sets. Our experiments provide evidence that class imbalance does not systematically hinder the performance of learning systems. In fact, the problem seems to be related to learning with too few minority class examples in the presence of other complicating factors, such as class overlapping. Two of our proposed methods deal with these conditions directly, allying a known over-sampling method with data cleaning methods in order to produce better-defined class clusters. Our comparative experiments show that, in general, over-sampling methods provide more accurate results than under-sampling methods considering the area under the ROC curve (AUC). This result seems to contradict results previously published in the literature. Two of our proposed methods, Smote + Tomek and Smote + ENN, presented very good results for data sets with a small number of positive examples. Moreover, Random over-sampling, a very simple over-sampling method, is very competitive to more complex over-sampling methods. Since the over-sampling methods provided very good performance results, we also measured the syntactic complexity of the decision trees induced from over-sampled data. Our results show that these trees are usually more complex then the ones induced from original data. Random over-sampling usually produced the smallest increase in the mean number of induced rules and Smote + ENN the smallest increase in the mean number of conditions per rule, when compared among the investigated over-sampling methods.},
  file = {/home/architect/Zotero/storage/HFYZYGXB/Batista et al. - 2004 - A study of the behavior of several methods for bal.pdf}
}
% == BibLateX quality report for batistaStudyBehaviorSeveral2004:
% Unexpected field 'publisher'

@inproceedings{baudischFishnetFisheyeWeb2004,
  title = {Fishnet, a {{Fisheye Web Browser}} with {{Search Term Popouts}}: {{A Comparative Evaluation}} with {{Overview}} and {{Linear View}}},
  shorttitle = {Fishnet, a {{Fisheye Web Browser}} with {{Search Term Popouts}}},
  booktitle = {Proceedings of the {{Working Conference}} on {{Advanced Visual Interfaces}}},
  author = {Baudisch, Patrick and Lee, Bongshin and Hanna, Libby},
  date = {2004},
  pages = {133--140},
  publisher = {{ACM}},
  location = {{Gallipoli, Italy}},
  doi = {10.1145/989863.989883},
  abstract = {Fishnet is a web browser that always displays web pages in their entirety, independent of their size. Fishnet accomplishes this by using a fisheye view, i.e. by showing a focus region at readable scale while spatially compressing page content above and below that region. Fishnet offers search term highlighting, and assures that those terms are readable by using "popouts". This allows users to visually scan search results within the entire page without scrolling.The scope of this paper is twofold. First, we present fishnet as a novel way of viewing the results of highlighted search and we discuss the design space. Second, we present a user study that helps practitioners determine which visualization technique--- fisheye view, overview, or regular linear view---to pick for which type of visual search scenario.},
  file = {/home/architect/Zotero/storage/QX3IZH39/Baudisch et al. - 2004 - Fishnet, a Fisheye Web Browser with Search Term Po.pdf;/home/architect/Zotero/storage/K3EK6YUA/baudisch2004.html},
  isbn = {978-1-58113-867-2},
  keywords = {fisheye view,popouts,search terms,web browser},
  series = {{{AVI}} '04}
}
% == BibLateX quality report for baudischFishnetFisheyeWeb2004:
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{berardiSemiAutomatedTextClassification2015,
  title = {Semi-{{Automated Text Classification}} for {{Sensitivity Identification}}},
  booktitle = {Proceedings of the 24th {{ACM International}} on {{Conference}} on {{Information}} and {{Knowledge Management}}},
  author = {Berardi, Giacomo and Esuli, Andrea and Macdonald, Craig and Ounis, Iadh and Sebastiani, Fabrizio},
  date = {2015-10-17},
  pages = {1711--1714},
  publisher = {{Association for Computing Machinery}},
  location = {{Melbourne, Australia}},
  doi = {10.1145/2806416.2806597},
  abstract = {Sensitive documents are those that cannot be made public, e.g., for personal or organizational privacy reasons. For instance, documents requested through Freedom of Information mechanisms must be manually reviewed for the presence of sensitive information before their actual release. Hence, tools that can assist human reviewers in spotting sensitive information are of great value to government organizations subject to Freedom of Information laws. We look at sensitivity identification in terms of semi-automated text classification (SATC), the task of ranking automatically classified documents so as to optimize the cost-effectiveness of human post-checking work. We use a recently proposed utility-theoretic approach to SATC that explicitly optimizes the chosen effectiveness function when ranking the documents by sensitivity; this is especially useful in our case, since sensitivity identification is a recall-oriented task, thus requiring the use of a recall-oriented evaluation measure such as F2. We show the validity of this approach by running experiments on a multi-label multi-class dataset of government documents manually annotated according to different types of sensitivity.},
  file = {/home/architect/Zotero/storage/PDPVZRC5/Berardi et al. - 2015 - Semi-Automated Text Classification for Sensitivity.pdf},
  isbn = {978-1-4503-3794-6},
  keywords = {semi-automated text classification,sensitive information},
  series = {{{CIKM}} '15}
}
% == BibLateX quality report for berardiSemiAutomatedTextClassification2015:
% ? Title looks like it was stored in title-case in Zotero

@collection{binderReSearchingDigital2009,
  title = {({{Re}})Searching the Digital {{Bauhaus}}},
  editor = {Binder, Thomas and L\"owgren, Jonas and Malmborg, Lone},
  date = {2009},
  publisher = {{Springer}},
  location = {{London}},
  file = {/home/architect/Zotero/storage/KBQSBJUI/Binder et al. - 2009 - (Re)searching the digital Bauhaus.pdf},
  isbn = {978-1-84800-349-1 978-1-84800-350-7},
  keywords = {Design,Human-computer interaction,User interfaces (Computer systems),User-centered system design},
  langid = {english},
  note = {OCLC: ocn233933002},
  pagetotal = {371},
  series = {Human-Computer Interaction Series}
}
% == BibLateX quality report for binderReSearchingDigital2009:
% 'isbn': not a valid ISBN

@misc{boettigerIntroductionDockerReproducible2015,
  title = {An Introduction to {{Docker}} for Reproducible Research},
  author = {Boettiger, Carl},
  date = {2015-01-20},
  publisher = {{Association for Computing Machinery}},
  url = {http://doi.org/10.1145/2723872.2723882},
  urldate = {2020-03-31},
  abstract = {As computational work becomes more and more integral to many aspects of scientific research, computational reproducibility has become an issue of increasing importance to computer systems researchers and domain scientists alike. Though computational reproducibility seems more straight forward than replicating physical experiments, the complex and rapidly changing nature of computer environments makes being able to reproduce and extend such work a serious challenge. In this paper, I explore common reasons that code developed for one research project cannot be successfully executed or extended by subsequent researchers. I review current approaches to these issues, including virtual machines and workflow systems, and their limitations. I then examine how the popular emerging technology Docker combines several areas from systems research - such as operating system virtualization, cross-platform portability, modular re-usable elements, versioning, and a 'DevOps' philosophy, to address these challenges. I illustrate this with several examples of Docker use with a focus on the R statistical environment.},
  file = {/home/architect/Zotero/storage/G6M9QSAZ/Boettiger - 2015 - An introduction to Docker for reproducible researc.pdf}
}
% == BibLateX quality report for boettigerIntroductionDockerReproducible2015:
% Unexpected field 'publisher'

@online{bostockFisheyeDistortion2012,
  title = {Fisheye {{Distortion}}},
  author = {Bostock, Mike},
  date = {2012},
  url = {https://bost.ocks.org/mike/fisheye/},
  urldate = {2019-12-10},
  file = {/home/architect/Zotero/storage/BYJVYDTQ/fisheye.html}
}
% == BibLateX quality report for bostockFisheyeDistortion2012:
% ? Title looks like it was stored in title-case in Zotero

@online{bostockFisheyeGrid2019,
  title = {Fisheye {{Grid}}},
  author = {Bostock, Mike},
  date = {2019},
  url = {https://bl.ocks.org/mbostock/2962761},
  urldate = {2019-12-10},
  abstract = {Mike Bostock's Block 2962761},
  file = {/home/architect/Zotero/storage/CRY47BDI/2962761.html}
}
% == BibLateX quality report for bostockFisheyeGrid2019:
% ? Title looks like it was stored in title-case in Zotero

@article{britoMonoreposMultivocalLiterature2018,
  ids = {britoMonoreposMultivocalLiterature2018a},
  title = {Monorepos: {{A Multivocal Literature Review}}},
  shorttitle = {Monorepos},
  author = {Brito, Gleison and Terra, Ricardo and Valente, Marco Tulio},
  date = {2018-10-22},
  url = {http://arxiv.org/abs/1810.09477},
  urldate = {2020-03-29},
  abstract = {Monorepos (Monolithic Repositories) are used by large companies, such as Google and Facebook, and by popular open-source projects, such as Babel and Ember. This study provides an overview on the definition and characteristics of monorepos as well as on their benefits and challenges. Thereupon, we conducted a multivocal literature review on mostly grey literature. Our findings are fourfold. First, monorepos are single repositories that contains multiple projects, related or unrelated, sharing the same dependencies. Second, centralization and standardization are some key characteristics. Third, the main benefits include simplified dependencies, coordination of cross-project changes, and easy refactoring. Fourth, code health, codebase complexity, and tooling investments for both development and execution are considered the main challenges.},
  archivePrefix = {arXiv},
  eprint = {1810.09477},
  eprinttype = {arxiv},
  file = {/home/architect/Zotero/storage/796QZRXS/Brito et al. - 2018 - Monorepos A Multivocal Literature Review.pdf;/home/architect/Zotero/storage/WPIEIFLM/Brito et al. - 2018 - Monorepos A Multivocal Literature Review.pdf;/home/architect/Zotero/storage/FM82UEUJ/1810.html},
  keywords = {Computer Science - Software Engineering,No DOI found},
  langid = {english},
  primaryClass = {cs}
}
% == BibLateX quality report for britoMonoreposMultivocalLiterature2018:
% Unexpected field 'archivePrefix'
% Unexpected field 'primaryClass'
% Missing required field 'journaltitle'
% ? Title looks like it was stored in title-case in Zotero

@article{brownPeekingBlackBox2015,
  title = {Peeking inside the {{Black Box}}: {{A Preliminary Survey}} of {{Technology Assisted Review}} ({{TAR}}) and {{Predictive Coding Algorithms}} for {{Ediscovery}}},
  shorttitle = {Peeking inside the {{Black Box}}},
  author = {Brown, Shannon},
  date = {2015/2016},
  journaltitle = {Suffolk Journal of Trial \& Appellate Advocacy},
  shortjournal = {Suffolk J. Trial \& App. Advoc.},
  volume = {21},
  pages = {221--288},
  url = {https://heinonline.org/HOL/P?h=hein.journals/sujoriapv21&i=242},
  urldate = {2020-03-15},
  file = {/home/architect/Zotero/storage/EQ8EE6IJ/Brown - 2015 - Peeking inside the Black Box A Preliminary Survey.pdf},
  langid = {english},
  number = {2}
}
% == BibLateX quality report for brownPeekingBlackBox2015:
% ? Title looks like it was stored in title-case in Zotero

@article{bucknerVisualizationTechniques,
  title = {Visualization {{Techniques}}},
  author = {Buckner, Nickie},
  pages = {6},
  abstract = {Many techniques have been described for viewing and exploring large information spaces. Often times these large data sets are represented in some hierarchical form. It is presumable that the same techniques that are effective for viewing general hierarchical structures would also be apt at displaying the Hierarchical Plans generated by many Artificial Intelligence Planning Systems. By surveying the current techniques available for visualizing general hierarchical information structures, hopefully a foundation will be laid for deriving equally effective techniques for the visualization of hierarchical plans and possibly plan search spaces.},
  file = {/home/architect/Zotero/storage/UTZLQEZD/Buckner - Visualization Techniques.pdf},
  keywords = {No DOI found},
  langid = {english}
}
% == BibLateX quality report for bucknerVisualizationTechniques:
% Exactly one of 'date' / 'year' must be present
% Missing required field 'journaltitle'
% ? Title looks like it was stored in title-case in Zotero

@article{buiAnalysisDockerSecurity2015,
  title = {Analysis of {{Docker Security}}},
  author = {Bui, Thanh},
  date = {2015-01-13},
  url = {http://arxiv.org/abs/1501.02967},
  urldate = {2020-03-31},
  abstract = {Over the last few years, the use of virtualization technologies has increased dramatically. This makes the demand for efficient and secure virtualization solutions become more obvious. Container-based virtualization and hypervisor-based virtualization are two main types of virtualization technologies that have emerged to the market. Of these two classes, container-based virtualization is able to provide a more lightweight and efficient virtual environment, but not without security concerns. In this paper, we analyze the security level of Docker, a well-known representative of container-based approaches. The analysis considers two areas: (1) the internal security of Docker, and (2) how Docker interacts with the security features of the Linux kernel, such as SELinux and AppArmor, in order to harden the host system. Furthermore, the paper also discusses and identifies what could be done when using Docker to increase its level of security.},
  archivePrefix = {arXiv},
  eprint = {1501.02967},
  eprinttype = {arxiv},
  file = {/home/architect/Zotero/storage/ZL97XVDY/Bui - 2015 - Analysis of Docker Security.pdf;/home/architect/Zotero/storage/Y8V5YABI/1501.html},
  keywords = {Computer Science - Cryptography and Security,No DOI found},
  primaryClass = {cs}
}
% == BibLateX quality report for buiAnalysisDockerSecurity2015:
% Unexpected field 'archivePrefix'
% Unexpected field 'primaryClass'
% Missing required field 'journaltitle'
% ? Title looks like it was stored in title-case in Zotero

@software{camachoMcamacReacttextannotate2020,
  title = {Mcamac/React-Text-Annotate},
  author = {Camacho, Martin},
  date = {2020-03-02T02:34:54Z},
  origdate = {2018-04-07T22:06:52Z},
  url = {https://github.com/mcamac/react-text-annotate},
  urldate = {2020-04-03},
  abstract = {React components for interactively highlighting parts of text.},
  keywords = {react}
}
% == BibLateX quality report for camachoMcamacReacttextannotate2020:
% Unexpected field 'title'
% Unexpected field 'author'
% ? Title looks like it was stored in lower-case in Zotero

@online{caplan-brickerChallengePreservingHistorical,
  title = {The {{Challenge}} of {{Preserving}} the {{Historical Record}} of \#{{MeToo}}},
  author = {Caplan-Bricker, Nora},
  journaltitle = {The New Yorker},
  url = {https://www.newyorker.com/tech/annals-of-technology/the-challenge-of-preserving-the-historical-record-of-metoo},
  urldate = {2020-02-16},
  abstract = {Evidence of the social-media movement should be collected, both because it matters and because it could disappear. But archivists face a battery of technical and ethical questions with few precedents.},
  file = {/home/architect/Zotero/storage/CG5LVMUB/the-challenge-of-preserving-the-historical-record-of-metoo.html},
  langid = {english}
}
% == BibLateX quality report for caplan-brickerChallengePreservingHistorical:
% Unexpected field 'journaltitle'
% Exactly one of 'date' / 'year' must be present
% ? Title looks like it was stored in title-case in Zotero

@article{carrollGrossmancormackGlossaryTechnologyassisted2013,
  title = {The Grossman-Cormack Glossary of Technology-Assisted Review},
  author = {Carroll, Lewis},
  date = {2013},
  journaltitle = {Federal Courts Law Review},
  shortjournal = {Fed. Courts Law Rev.},
  volume = {7},
  file = {/home/architect/Zotero/storage/4254UGYU/Carroll - 2013 - The grossman-cormack glossary of technology-assist.pdf},
  keywords = {No DOI found},
  number = {1}
}

@software{Celery2020,
  title = {Celery},
  date = {2020-04-04T16:48:58Z},
  origdate = {2009-04-24T11:31:24Z},
  url = {https://github.com/celery/celery},
  urldate = {2020-04-04},
  abstract = {Distributed Task Queue (development branch). Contribute to celery/celery development by creating an account on GitHub.},
  keywords = {amqp,python,python-library,python2,python3,queue-tasks,queue-workers,queued-jobs,redis,sqs,sqs-queue,task-manager,task-runner,task-scheduler},
  organization = {{Celery}}
}
% == BibLateX quality report for Celery2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@article{changLIBSVMLibrarySupport2011,
  title = {{{LIBSVM}}: {{A}} Library for Support Vector Machines},
  shorttitle = {{{LIBSVM}}},
  author = {Chang, Chih-Chung and Lin, Chih-Jen},
  date = {2011-04-01},
  journaltitle = {ACM Transactions on Intelligent Systems and Technology},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  volume = {2},
  pages = {1--27},
  issn = {21576904},
  doi = {10.1145/1961189.1961199},
  abstract = {LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems, theoretical convergence, multi-class classification, probability estimates, and parameter selection are discussed in detail.},
  file = {/home/architect/Zotero/storage/UIHDLH6C/Chang and Lin - 2011 - LIBSVM A library for support vector machines.pdf},
  langid = {english},
  number = {3}
}

@article{chenXGBoostScalableTree2016,
  title = {{{XGBoost}}: {{A Scalable Tree Boosting System}}},
  shorttitle = {{{XGBoost}}},
  author = {Chen, Tianqi and Guestrin, Carlos},
  date = {2016},
  journaltitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '16},
  shortjournal = {Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discov. Data Min. - KDD 16},
  pages = {785--794},
  doi = {10.1145/2939672.2939785},
  abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
  archivePrefix = {arXiv},
  eprint = {1603.02754},
  eprinttype = {arxiv},
  file = {/home/architect/Zotero/storage/WYFN52FZ/Chen and Guestrin - 2016 - XGBoost A Scalable Tree Boosting System.pdf;/home/architect/Zotero/storage/SZHDLUGI/1603.html},
  keywords = {Computer Science - Machine Learning}
}
% == BibLateX quality report for chenXGBoostScalableTree2016:
% Unexpected field 'archivePrefix'
% ? Title looks like it was stored in title-case in Zotero

@patent{chowMethodApparatusFacilitating2013,
  title = {Method and Apparatus for Facilitating Document Sanitization},
  author = {Chow, Richard and Staddon, Jessica N. and Oberst, Ian S.},
  date = {2013-10-22},
  url = {https://patents.google.com/patent/US8566350B2/en},
  urldate = {2019-12-10},
  file = {/home/architect/Zotero/storage/SJBAASTU/Chow et al. - 2013 - Method and apparatus for facilitating document san.pdf},
  holder = {{Palo Alto Research Center Inc}},
  keywords = {determining,document,modified version,term,terms},
  langid = {english},
  number = {8566350B2},
  type = {patentus}
}

@software{Codeclimate2020,
  title = {Codeclimate},
  date = {2020-03-28T18:26:17Z},
  origdate = {2015-06-19T13:54:41Z},
  url = {https://github.com/codeclimate/codeclimate},
  urldate = {2020-03-29},
  abstract = {Code Climate CLI. Contribute to codeclimate/codeclimate development by creating an account on GitHub.},
  keywords = {climate-cli,code-quality,codeclimate,codeclimate-engine,docker,quality,static-analysis,static-code-analysis},
  organization = {{Code Climate}}
}
% == BibLateX quality report for Codeclimate2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@software{Codecov2020,
  title = {Codecov},
  shorttitle = {Codecov},
  date = {2020},
  url = {https://codecov.io},
  urldate = {2020-03-29},
  abstract = {Develop healthier code using Codecov's leading, dedicated code coverage solution. Try it free},
  file = {/home/architect/Zotero/storage/AL63JSDM/codecov.io.html},
  note = {Library Catalog: codecov.io}
}
% == BibLateX quality report for Codecov2020:
% Unexpected field 'title'
% Unexpected field 'note'

@article{collinsDocuBurstVisualizingDocument2009,
  title = {{{DocuBurst}}: {{Visualizing Document Content}} Using {{Language Structure}}},
  shorttitle = {{{DocuBurst}}},
  author = {Collins, Christopher and Carpendale, Sheelagh and Penn, Gerald},
  date = {2009},
  journaltitle = {Computer Graphics Forum},
  shortjournal = {Comput. Graph. Forum},
  volume = {28},
  pages = {1039--1046},
  issn = {1467-8659},
  doi = {10.1111/j.1467-8659.2009.01439.x},
  abstract = {Textual data is at the forefront of information management problems today. One response has been the development of visualizations of text data. These visualizations, commonly based on simple attributes such as relative word frequency, have become increasingly popular tools. We extend this direction, presenting the first visualization of document content which combines word frequency with the human-created structure in lexical databases to create a visualization that also reflects semantic content. DocuBurst is a radial, space-filling layout of hyponymy (the IS-A relation), overlaid with occurrence counts of words in a document of interest to provide visual summaries at varying levels of granularity. Interactive document analysis is supported with geometric and semantic zoom, selectable focus on individual words, and linked access to source text.},
  file = {/home/architect/Zotero/storage/K32NYILX/Collins et al. - 2009 - DocuBurst Visualizing Document Content using Lang.pdf;/home/architect/Zotero/storage/P6GBVIGR/j.1467-8659.2009.01439.html},
  keywords = {Computer Graphics I.3.6: Methodology and Techniques-Interaction Techniques,Document And Text Processing I.7.1: Document and Text Editing-Document Management,Information Storage and Retrieval H.3.7: Digital Libraries-User Issues},
  langid = {english},
  number = {3}
}

@legislation{ConstitutionalReformGovernance2010,
  title = {Constitutional {{Reform}} and {{Governance Act}}},
  date = {2010},
  pages = {32},
  url = {http://www.legislation.gov.uk/ukpga/2010/25/data.pdf},
  file = {/home/architect/Zotero/storage/5ZC788ZM/2010 - Constitutional Reform and Governance Act 2010.pdf},
  langid = {english},
  number = {2010 CHAPTER 25}
}
% == BibLateX quality report for ConstitutionalReformGovernance2010:
% Unexpected field 'title'
% Unexpected field 'pages'
% Unexpected field 'number'
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{cormackEvaluationMachinelearningProtocols2014,
  title = {Evaluation of Machine-Learning Protocols for Technology-Assisted Review in Electronic Discovery},
  booktitle = {Proceedings of the 37th International {{ACM SIGIR}} Conference on {{Research}} \& Development in Information Retrieval},
  author = {Cormack, Gordon V. and Grossman, Maura R.},
  date = {2014-07-03},
  pages = {153--162},
  publisher = {{Association for Computing Machinery}},
  location = {{Gold Coast, Queensland, Australia}},
  doi = {10.1145/2600428.2609601},
  abstract = {Abstract Using a novel evaluation toolkit that simulates a human reviewer in the loop, we compare the effectiveness of three machine-learning protocols for technology-assisted review as used in document review for discovery in legal proceedings. Our comparison addresses a central question in the deployment of technology-assisted review: Should training documents be selected at random, or should they be selected using one or more non-random methods, such as keyword search or active learning? On eight review tasks -- four derived from the TREC 2009 Legal Track and four derived from actual legal matters -- recall was measured as a function of human review effort. The results show that entirely non-random training methods, in which the initial training documents are selected using a simple keyword search, and subsequent training documents are selected by active learning, require substantially and significantly less human review effort (P{$<$}0.01) to achieve any given level of recall, than passive learning, in which the machine-learning algorithm plays no role in the selection of training documents. Among passive-learning methods, significantly less human review effort (P{$<$}0.01) is required when keywords are used instead of random sampling to select the initial training documents. Among active-learning methods, continuous active learning with relevance feedback yields generally superior results to simple active learning with uncertainty sampling, while avoiding the vexing issue of "stabilization" -- determining when training is adequate, and therefore may stop.},
  file = {/home/architect/Zotero/storage/8LZ5P8FJ/Cormack and Grossman - 2014 - Evaluation of machine-learning protocols for techn.pdf;/home/architect/Zotero/storage/RTCKPZX9/Cormack and Grossman - 2014 - Evaluation of machine-learning protocols for techn.pdf},
  isbn = {978-1-4503-2257-7},
  keywords = {e-discovery,electronic discovery,predictive coding,technology-assisted review},
  series = {{{SIGIR}} '14}
}
% == BibLateX quality report for cormackEvaluationMachinelearningProtocols2014:
% ? Unsure about the formatting of the booktitle

@inproceedings{cormackMachineLearningInformation2009,
  title = {Machine {{Learning}} for {{Information Retrieval}}: {{TREC}} 2009 {{Web}}, {{Relevance Feedback}} and {{Legal Tracks}}.},
  shorttitle = {Machine {{Learning}} for {{Information Retrieval}}},
  author = {Cormack, Gordon and Mojdeh, Mona},
  date = {2009-01-01},
  file = {/home/architect/Zotero/storage/LJL4HH4V/Cormack and Mojdeh - Machine Learning for Information Retrieval TREC 2.pdf}
}
% == BibLateX quality report for cormackMachineLearningInformation2009:
% Missing required field 'booktitle'
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{cumbyMachineLearningBased2011,
  title = {A {{Machine Learning Based System}} for {{Semi}}-{{Automatically Redacting Documents}}},
  booktitle = {{{IAAI}}},
  author = {Cumby, Chad M. and Ghani, Rayid},
  date = {2011},
  pages = {8},
  abstract = {Redacting text documents has traditionally been a mostly manual activity, making it expensive and prone to disclosure risks. This paper describes a semi-automated system to ensure a specified level of privacy in text data sets. Recent work has attempted to quantify the likelihood of privacy breaches for text data. We build on these notions to provide a means of obstructing such breaches by framing it as a multi-class classification problem. Our system gives users fine-grained control over the level of privacy needed to obstruct sensitive concepts present in that data. Additionally, our system is designed to respect a user-defined utility metric on the data (such as disclosure of a particular concept), which our methods try to maximize while anonymizing. We describe our redaction framework, algorithms, as well as a prototype tool built in to Microsoft Word that allows enterprise users to redact documents before sharing them internally and obscure client specific information. In addition we show experimental evaluation using publicly available data sets that show the effectiveness of our approach against both automated attackers and human subjects.The results show that we are able to preserve the utility of a text corpus while reducing disclosure risk of the sensitive concept.},
  file = {/home/architect/Zotero/storage/DERSJ2XQ/Cumby and Ghani - A Machine Learning Based System for Semi-Automatic.pdf},
  langid = {english}
}
% == BibLateX quality report for cumbyMachineLearningBased2011:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero

@online{DemoRedactedAi,
  title = {Demo of {{Redacted}}.Ai {{Technology}}},
  journaltitle = {Vimeo},
  url = {https://vimeo.com/306115629},
  urldate = {2020-03-26},
  abstract = {This is a video walkthrough of how to use the special demo version of Redacted.ai. The demo version is a scaled down version of the software meant to allow perspective\ldots{}},
  file = {/home/architect/Zotero/storage/DGI3M7HV/306115629.html},
  langid = {english},
  note = {Library Catalog: vimeo.com}
}
% == BibLateX quality report for DemoRedactedAi:
% Unexpected field 'journaltitle'
% Exactly one of 'date' / 'year' must be present

@software{Dependabot2020,
  title = {Dependabot},
  date = {2020-03-29T13:08:17Z},
  origdate = {2017-06-02T12:23:31Z},
  url = {https://dependabot.com/},
  urldate = {2020-03-29},
  abstract = {ðŸ¤–The core logic behind Dependabot's update PR creation},
  keywords = {dependencies,docker,dotnet,elixir,elm,go,java,javascript,php,python,ruby,rust,terraform},
  organization = {{Dependabot}}
}
% == BibLateX quality report for Dependabot2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@article{diamantidisUnsupervisedStratificationCrossvalidation2000,
  title = {Unsupervised Stratification of Cross-Validation for Accuracy Estimation},
  author = {Diamantidis, N. A. and Karlis, D. and Giakoumakis, E. A.},
  date = {2000-01-01},
  journaltitle = {Artificial Intelligence},
  shortjournal = {Artificial Intelligence},
  volume = {116},
  pages = {1--16},
  issn = {0004-3702},
  doi = {10.1016/s0004-3702(99)00094-6},
  abstract = {The rapid development of new learning algorithms increases the need for improved accuracy estimation methods. Moreover, methods allowing the comparison of several different learning algorithms are important for the performance evaluation of new ones. In this paper we propose new accuracy estimation methods which are extensions of the k-fold cross-validation method. The methods proposed construct cross-validation folds deterministically instead of using the random sampling approach. The deterministic construction of folds is performed using unsupervised stratification by exploiting the distribution of instances in the instance space. Our methods are based either on the one-center approach or on clustering procedures. These methods attempt to construct more representative folds, therefore reducing the bias of the resulting estimator. At the same time, our methods allow direct comparisons between the performance of learning algorithms in different experiments, since no randomness is present. A simulation experiment examining the performance of the proposed methods is reported, depicting their behavior in a variety of situations. The new methods reduce mainly the bias of the estimator.},
  file = {/home/architect/Zotero/storage/RDD247PJ/Diamantidis et al. - 2000 - Unsupervised stratification of cross-validation fo.pdf;/home/architect/Zotero/storage/ICSWZANM/S0004370299000946.html},
  keywords = {Accuracy estimation,Clustering,Cross-validation,Inductive learning,Machine learning},
  langid = {english},
  number = {1}
}

@software{dillonHopdingPdflib2020,
  title = {Hopding/Pdf-Lib},
  author = {Dillon, Andrew},
  date = {2020-04-03T05:36:22Z},
  origdate = {2017-09-04T14:22:30Z},
  url = {https://github.com/Hopding/pdf-lib},
  urldate = {2020-04-03},
  abstract = {Create and modify PDF documents in any JavaScript environment},
  keywords = {copy,copying,create,creation,document,edit,editing,javascript,javascript-environment,library,modification,modify,pdf,pdf-document,pdf-generation,pdf-lib,pdflib,typescript,umd}
}
% == BibLateX quality report for dillonHopdingPdflib2020:
% Unexpected field 'title'
% Unexpected field 'author'
% ? Title looks like it was stored in lower-case in Zotero

@software{DmlcXgboost2020,
  title = {Dmlc/Xgboost},
  date = {2020-04-03T12:30:27Z},
  origdate = {2014-02-06T17:28:03Z},
  url = {https://github.com/dmlc/xgboost},
  urldate = {2020-04-03},
  abstract = {Scalable, Portable and Distributed Gradient Boosting (GBDT, GBRT or GBM) Library,  for Python, R, Java, Scala, C++ and more. Runs on single machine, Hadoop, Spark, Flink and DataFlow},
  keywords = {distributed-systems,gbdt,gbm,gbrt,machine-learning,xgboost},
  organization = {{Distributed (Deep) Machine Learning Community}}
}
% == BibLateX quality report for DmlcXgboost2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@software{Docker2020,
  title = {Docker},
  date = {2020-03-30T13:28:05Z},
  origdate = {2017-05-19T23:09:47Z},
  url = {https://github.com/docker/docker-ce},
  urldate = {2020-03-31},
  abstract = {Docker CE. Contribute to docker/docker-ce development by creating an account on GitHub.},
  keywords = {docker,git,golang,moby},
  organization = {{Docker}}
}
% == BibLateX quality report for Docker2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@software{DockerCompose2020,
  title = {Docker/Compose},
  date = {2020-03-31T03:33:41Z},
  origdate = {2013-12-09T11:40:58Z},
  url = {https://github.com/docker/compose},
  urldate = {2020-03-31},
  abstract = {Define and run multi-container applications with Docker},
  keywords = {docker,docker-compose,orchestration,python},
  organization = {{Docker}}
}
% == BibLateX quality report for DockerCompose2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@online{DockerHub,
  title = {Docker {{Hub}}},
  date = {2020},
  url = {https://hub.docker.com/},
  urldate = {2020-03-31},
  file = {/home/architect/Zotero/storage/ECPLY4U4/hub.docker.com.html}
}
% == BibLateX quality report for DockerHub:
% ? Title looks like it was stored in title-case in Zotero

@article{el-assadyProgressiveLearningTopic2018,
  title = {Progressive {{Learning}} of {{Topic Modeling Parameters}}: {{A Visual Analytics Framework}}},
  shorttitle = {Progressive {{Learning}} of {{Topic Modeling Parameters}}},
  author = {El-Assady, Mennatallah and Sevastjanova, Rita and Sperrle, Fabian and Keim, Daniel and Collins, Christopher},
  date = {2018-01},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  shortjournal = {IEEE Trans. Visual. Comput. Graphics},
  volume = {24},
  pages = {382--391},
  issn = {1077-2626},
  doi = {10.1109/tvcg.2017.2745080},
  abstract = {Topic modeling algorithms are widely used to analyze the thematic composition of text corpora but remain difficult to interpret and adjust. Addressing these limitations, we present a modular visual analytics framework, tackling the understandability and adaptability of topic models through a user-driven reinforcement learning process which does not require a deep understanding of the underlying topic modeling algorithms. Given a document corpus, our approach initializes two algorithm configurations based on a parameter space analysis that enhances document separability. We abstract the model complexity in an interactive visual workspace for exploring the automatic matching results of two models, investigating topic summaries, analyzing parameter distributions, and reviewing documents. The main contribution of our work is an iterative decision-making technique in which users provide a document-based relevance feedback that allows the framework to converge to a user-endorsed topic distribution. We also report feedback from a two-stage study which shows that our technique results in topic model quality improvements on two independent measures.},
  file = {/home/architect/Zotero/storage/6V33HR6N/El-Assady et al. - 2018 - Progressive Learning of Topic Modeling Parameters.pdf;/home/architect/Zotero/storage/X7WZ9QES/el-assady2017.html},
  langid = {english},
  number = {1}
}
% == BibLateX quality report for el-assadyProgressiveLearningTopic2018:
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{el-assadyVisArgueVisualText2016,
  title = {{{VisArgue}} : {{A Visual Text Analytics Framework}} for the {{Study}} of {{Deliberative Communication}}},
  shorttitle = {{{VisArgue}}},
  author = {El-Assady, Mennatallah and Gold, Valentin and Hautli-Janisz, Annette and Jentner, Wolfgang and Butt, Miriam and Holzinger, Katharina and Keim, Daniel A.},
  date = {2016},
  pages = {31--36},
  url = {https://kops.uni-konstanz.de/handle/123456789/37650},
  urldate = {2019-12-10},
  abstract = {For the last two decades, deliberative democracy has been intensively debated within political science and other related fields. Only recently, deliberation research has experienced a computational turn. In this paper, we present a linguistic and visual framework for the study of deliberative communication. The framework includes a range of visual analytics approaches to support research into deliberation. In particular, we propose a range of visualizations for highlighting deliberative patterns over time, speakers, and debates.},
  eventtitle = {{{PolText}} 2016 - {{The International Conference}} on the {{Advancesin Computational Analysis}} of {{Political Text}}},
  file = {/home/architect/Zotero/storage/2TGZFDSV/El-Assady et al. - 2016 - VisArgue  A Visual Text Analytics Framework for t.pdf;/home/architect/Zotero/storage/56CFQGHI/37650.html},
  isbn = {978-953-6457-92-2},
  langid = {english}
}
% == BibLateX quality report for el-assadyVisArgueVisualText2016:
% Missing required field 'booktitle'
% ? Title looks like it was stored in title-case in Zotero

@software{ElasticElasticsearch2020,
  title = {Elastic/Elasticsearch},
  date = {2020-04-06T09:26:53Z},
  origdate = {2010-02-08T13:20:56Z},
  url = {https://github.com/elastic/elasticsearch},
  urldate = {2020-04-06},
  abstract = {Open Source, Distributed, RESTful Search Engine. Contribute to elastic/elasticsearch development by creating an account on GitHub.},
  keywords = {elasticsearch,java,search-engine},
  organization = {{elastic}}
}
% == BibLateX quality report for ElasticElasticsearch2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@book{EncyclopediaHumanComputerInteraction,
  title = {The {{Encyclopedia}} of {{Human}}-{{Computer Interaction}}, 2nd {{Ed}}.},
  url = {https://www.interaction-design.org/literature/book/the-encyclopedia-of-human-computer-interaction-2nd-ed},
  urldate = {2019-12-10},
  abstract = {The Encyclopedia of Human-Computer Interaction, 2nd Ed.. Free textbooks written by more than 100 leading designers, bestselling authors, and Ivy League professors. We have assembled our textbooks in a gigantic encyclopedia, whose 4,000+ pages cover the design of interactive products and services such as websites, household objects, smartphones, computer s...},
  file = {/home/architect/Zotero/storage/N8VYB2GS/the-encyclopedia-of-human-computer-interaction-2nd-ed.html},
  langid = {english}
}
% == BibLateX quality report for EncyclopediaHumanComputerInteraction:
% Exactly one of 'date' / 'year' must be present
% Missing required field 'author'
% ? Title looks like it was stored in title-case in Zotero

@software{ERedact,
  title = {E-{{Redact}}},
  date = {2020},
  url = {https://e-redact.co.uk/},
  urldate = {2020-03-26},
  file = {/home/architect/Zotero/storage/L8A84UYY/e-redact.co.uk.html},
  organization = {{Footprint Solutions}}
}
% == BibLateX quality report for ERedact:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@software{FacebookReact2020,
  title = {Facebook/React},
  date = {2020},
  origdate = {2013-05-24T16:15:54Z},
  url = {https://github.com/facebook/react},
  urldate = {2020-03-20},
  abstract = {A declarative, efficient, and flexible JavaScript library for building user interfaces.},
  keywords = {declarative,frontend,javascript,library,react,ui},
  organization = {{Facebook}}
}
% == BibLateX quality report for FacebookReact2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@report{federalbureauofinvestigationClintonEemailInvestigation2016,
  title = {Clinton {{E}}-Email {{Investigation}}},
  author = {{Federal Bureau of Investigation}},
  date = {2016-07},
  pages = {47},
  institution = {{U.S. Department of Justice}},
  location = {{Washington, D.C.}},
  url = {https://vault.fbi.gov/hillary-r.-clinton/Hillary%20R.%20Clinton%20Part%2001%20of%2040},
  urldate = {2020-03-24},
  file = {/home/architect/Zotero/storage/TXQJXTGE/Hillary R.pdf},
  langid = {english}
}
% == BibLateX quality report for federalbureauofinvestigationClintonEemailInvestigation2016:
% Missing required field 'type'

@legislation{FreedomInformationAct2000,
  title = {Freedom of {{Information Act}}},
  date = {2000},
  pages = {173},
  abstract = {An Act to make provision for the disclosure of information held by public authorities or by persons providing services for them and to amend the Data Protection Act 1998 and the Public Records Act 1958; and for connected purposes.},
  file = {/home/architect/Zotero/storage/7LQ3QJ8H/2000 - Freedom of Information Act 2000.pdf},
  langid = {english},
  number = {2000 c. 36}
}
% == BibLateX quality report for FreedomInformationAct2000:
% Unexpected field 'title'
% Unexpected field 'pages'
% Unexpected field 'number'
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{goldExploratoryTextAnalysis2015,
  title = {Exploratory {{Text Analysis}} Using {{Lexical Episode Plots}}},
  author = {Gold, Valentin and Rohrdantz, Christian and El-Assady, Mennatallah},
  date = {2015},
  pages = {85--90},
  doi = {10.2312/eurovisshort.20151130},
  abstract = {In this paper, we present Lexical Episode Plots, a novel automated text-mining and visual analytics approach for exploratory text analysis. In particular, we first describe an algorithm for automatically annotating text regions to examine prominent themes within natural language texts. The algorithm is based on lexical chaining to find spans of text in which the frequency of a term is significantly higher than its average in the document. In a second step we present an interactive visualization supporting the exploration and interpretation of Lexical Episodes. The visualization links higher-level thematic structures with content-level details. The methodological capabilities of our approach are illustrated by analyzing the televised US presidential election debates.},
  eventtitle = {{{EuroVis}} : {{The EG}}/{{VGTC Conference}} on {{Visualization}}},
  file = {/home/architect/Zotero/storage/Y5GBB76G/Gold et al. - 2015 - Exploratory Text Analysis using Lexical Episode Pl.pdf;/home/architect/Zotero/storage/LF79AM99/32053.html},
  langid = {english}
}
% == BibLateX quality report for goldExploratoryTextAnalysis2015:
% Missing required field 'booktitle'

@article{gollinsUsingInformationRetrieval,
  title = {On {{Using Information Retrieval}} for the {{Selection}} and {{Sensitivity Review}} of {{Digital Public Records}}},
  author = {Gollins, Timothy and McDonald, Graham and Macdonald, Craig and Ounis, Iadh},
  pages = {2},
  file = {/home/architect/Zotero/storage/LCYTYGLW/Gollins et al. - On Using Information Retrieval for the Selection a.pdf;/home/architect/Zotero/storage/U9XJB7M3/Gollins et al. - On Using Information Retrieval for the Selection a.pdf},
  keywords = {â›” No DOI found,No DOI found},
  langid = {english}
}
% == BibLateX quality report for gollinsUsingInformationRetrieval:
% Exactly one of 'date' / 'year' must be present
% Missing required field 'journaltitle'
% ? Title looks like it was stored in title-case in Zotero

@software{GoogleContainerToolsDistroless2020,
  title = {{{GoogleContainerTools}}/Distroless},
  date = {2020-02-08T14:37:27Z},
  origdate = {2017-04-18T22:02:38Z},
  url = {https://github.com/GoogleContainerTools/distroless},
  urldate = {2020-02-08},
  abstract = {ðŸ¥‘  Language focused docker images, minus the operating system.},
  keywords = {bazel,docker},
  organization = {{GoogleContainerTools}}
}
% == BibLateX quality report for GoogleContainerToolsDistroless2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@inproceedings{greenbergFisheyeTextEditor1996,
  ids = {greenbergFisheyeTextEditor1996a},
  title = {A Fisheye Text Editor for Relaxed-{{WYSIWIS}} Groupware},
  booktitle = {Conference Companion on {{Human}} Factors in Computing Systems Common Ground - {{CHI}} '96},
  author = {Greenberg, Saul},
  date = {1996},
  pages = {212--213},
  publisher = {{ACM Press}},
  location = {{Vancouver, British Columbia, Canada}},
  doi = {10.1145/257089.257285},
  abstract = {Participants in a real-time groupware conference require a sense of awareness about other people's interactions within a large shared workspace. Fisheye views can afford this awareness by assigning a focal point to each participant. The fisheye effect around these multiple focal points provides peripheral awareness by showing people's location in the global context, and by magnifying the area around their work to highlight interaction details. An adjustable magnification function lets people customize the awareness information to fit their collaboration needs. A fisheye text editor illustrates how this can be accomplished.},
  eventtitle = {Conference Companion},
  file = {/home/architect/Zotero/storage/39EDATHR/Greenberg - 1996 - A fisheye text editor for relaxed-WYSIWIS groupwar.pdf;/home/architect/Zotero/storage/4C7ZA2BP/Greenberg - 1996 - A fisheye text editor for relaxed-WYSIWIS groupwar.pdf;/home/architect/Zotero/storage/3FPWJZES/greenberg1996.html;/home/architect/Zotero/storage/7ZBIXTWI/greenberg1996.html},
  isbn = {978-0-89791-832-9},
  langid = {english}
}

@online{greenwaldFactsHowNSA2014,
  title = {Some {{Facts About How NSA Stories Are Reported}}},
  author = {Greenwald, Glenn},
  date = {2014-03-23T10:41:51+00:00},
  journaltitle = {The Intercept},
  url = {https://theintercept.com/2014/03/23/facts-nsa-stories-reported/},
  urldate = {2020-04-04},
  file = {/home/architect/Zotero/storage/UGR75PB7/facts-nsa-stories-reported.html},
  langid = {american},
  note = {Library Catalog: The Intercept}
}
% == BibLateX quality report for greenwaldFactsHowNSA2014:
% Unexpected field 'journaltitle'
% ? Title looks like it was stored in title-case in Zotero

@article{greenwaldJournalistSaysExplosive2013,
  title = {Journalist {{Says Explosive Reports Coming}} from {{Snowden Data}}},
  author = {Greenwald, Glenn},
  date = {2013-07-19},
  journaltitle = {Der Spiegel},
  url = {https://www.spiegel.de/international/world/journalist-says-explosive-reports-coming-from-snowden-data-a-912034.html},
  urldate = {2020-03-24},
  abstract = {Journalist Glenn Greenwald says new reports from the trove of NSA data supplied by whistleblower Edward Snowden can be expected in the next few days. Speaking on a German talkshow, he said they would be even "more explosive in Germany" than previous reporting.},
  entrysubtype = {newspaper},
  file = {/home/architect/Zotero/storage/JBJHWNTG/consent-a-.html},
  langid = {english},
  note = {Library Catalog: www.spiegel.de}
}
% == BibLateX quality report for greenwaldJournalistSaysExplosive2013:
% ? Title looks like it was stored in title-case in Zotero

@book{greenwaldNoPlaceHide2014,
  title = {No {{Place}} to {{Hide}}: {{Edward Snowden}}, the {{NSA}} and the {{Surveillance State}}},
  shorttitle = {No {{Place}} to {{Hide}}},
  author = {Greenwald, Glenn},
  date = {2014-05-13},
  publisher = {{Penguin UK}},
  abstract = {THE INSIDE ACCOUNT OF THE EVENTS DOCUMENTED IN LAURA POITRAS'S CITIZENFOUR Glenn Greenwald's No Place to Hide is the story of one of the greatest national security leaks in US history.In June 2013, reporter and political commentator Glenn Greenwald published a series of reports in the Guardian which rocked the world.The reports revealed shocking truths about the extent to which the National Security Agency had been gathering information about US citizens and intercepting communication worldwide, and were based on documents leaked by former National Security Agency employee Edward Snowden to Greenwald.Including new revelations from documents entrusted to Greenwald by Snowden, this essential book tells the story of Snowden and the NSA and examines the far-reaching consequences of the government's surveillance program, both in the US and abroad.'The first thing I do when I turn on the computer in the morning is go to Glenn Greenwald's blog. He is truly one of our greatest writers right now' Michael Moore'The most important voice to have entered the political discourse in years' Bill MoyersGlenn Greenwald is the author of several US bestsellers, including How Would A Patriot Act?, and A Tragic Legacy. Acclaimed as one of the twenty-five most influential political commentators by The Atlantic, Greenwald is a former constitutional law and civil rights attorney. He has been a columnist for the Guardian since August 2012 and his work has appeared in numerous newspapers and political news magazines, including The New York Times and the Los Angeles Times.},
  isbn = {978-0-241-96900-7},
  keywords = {Political Science / Civil Rights,Political Science / Geopolitics,Political Science / Intelligence & Espionage},
  langid = {english},
  pagetotal = {340}
}
% == BibLateX quality report for greenwaldNoPlaceHide2014:
% ? Title looks like it was stored in title-case in Zotero

@article{grossmanTechnologyAssistedReviewEDiscovery2010,
  title = {Technology-{{Assisted Review}} in {{E}}-{{Discovery Can Be More Effective}} and {{More Efficient}} than {{Exhaustive Manual Review Annual Survey}}},
  author = {Grossman, Maura R. and Cormack, Gordon V.},
  date = {2010/2011},
  journaltitle = {Richmond Journal of Law and Technology},
  shortjournal = {Rich. J.L. \& Tech.},
  volume = {17},
  pages = {1--48},
  url = {https://heinonline.org/HOL/P?h=hein.journals/jolt17&i=471},
  urldate = {2020-03-15},
  file = {/home/architect/Zotero/storage/44YCUDBU/Grossman and Cormack - 2010 - Technology-Assisted Review in E-Discovery Can Be M.pdf},
  langid = {english},
  number = {3}
}
% == BibLateX quality report for grossmanTechnologyAssistedReviewEDiscovery2010:
% ? Title looks like it was stored in title-case in Zotero

@video{GTO703ShapleyValue,
  title = {{{GTO}}-7-03: {{The Shapley Value}}},
  shorttitle = {{{GTO}}-7-03},
  url = {https://www.youtube.com/watch?v=qcLZMYPdpH4},
  urldate = {2020-01-20},
  abstract = {This video from Game Theory Online (http://www.game-theory-class.org) defines the Shapley Value, a prominent way of dividing profits within a coalition based on a formal notion of marginal bargaining power.  It features Matt Jackson (Stanford).},
  keywords = {\#nosource}
}
% == BibLateX quality report for GTO703ShapleyValue:
% Unexpected field 'title'
% ? Title looks like it was stored in title-case in Zotero

@incollection{hartTextClassificationData2011,
  title = {Text {{Classification}} for {{Data Loss Prevention}}},
  booktitle = {Privacy {{Enhancing Technologies}}},
  author = {Hart, Michael and Manadhata, Pratyusa and Johnson, Rob},
  editor = {Fischer-H\"ubner, Simone and Hopper, Nicholas},
  date = {2011},
  volume = {6794},
  pages = {18--37},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-22263-4_2},
  abstract = {Businesses, governments, and individuals leak confidential information, both accidentally and maliciously, at tremendous cost in money, privacy, national security, and reputation. Several security software vendors now offer ``data loss prevention'' (DLP) solutions that use simple algorithms, such as keyword lists and hashing, which are too coarse to capture the features what makes sensitive documents secret. In this paper, we present automatic text classification algorithms for classifying enterprise documents as either sensitive or non-sensitive. We also introduce a novel training strategy, supplement and adjust, to create a classifier that has a low false discovery rate, even when presented with documents unrelated to the enterprise. We evaluated our algorithm on several corpora that we assembled from confidential documents published on WikiLeaks and other archives. Our classifier had a false negative rate of less than 3.0\% and a false discovery rate of less than 1.0\% on all our tests (i.e, in a real deployment, the classifier can identify more than 97\% of information leaks while raising at most 1 false alarm every 100th time).},
  editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
  editorbtype = {redactor},
  file = {/home/architect/Zotero/storage/263K5JG2/Hart et al. - 2011 - Text Classification for Data Loss Prevention.pdf},
  isbn = {978-3-642-22262-7 978-3-642-22263-4},
  langid = {english},
  note = {Series Title: Lecture Notes in Computer Science}
}
% == BibLateX quality report for hartTextClassificationData2011:
% 'isbn': not a valid ISBN
% ? Title looks like it was stored in title-case in Zotero

@book{hastieElementsStatisticalLearning2013,
  title = {The {{Elements}} of {{Statistical Learning}}: {{Data Mining}}, {{Inference}}, and {{Prediction}}},
  shorttitle = {The {{Elements}} of {{Statistical Learning}}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  date = {2013-11-11},
  publisher = {{Springer Science \& Business Media}},
  abstract = {During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It is a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting---the first comprehensive treatment of this topic in any book. This major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression \& path algorithms for the lasso, non-negative matrix factorization, and spectral clustering. There is also a chapter on methods for ``wide'' data (p bigger than n), including multiple testing and false discovery rates. Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie co-developed much of the statistical modeling software and environment in R/S-PLUS and invented principal curves and surfaces. Tibshirani proposed the lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, projection pursuit and gradient boosting.},
  eprint = {yPfZBwAAQBAJ},
  eprinttype = {googlebooks},
  file = {/home/architect/Zotero/storage/YCD4HAJF/Hastie et al. - 2013 - The Elements of Statistical Learning Data Mining,.pdf},
  isbn = {978-0-387-21606-5},
  keywords = {Computers / Databases / General,Computers / Intelligence (AI) & Semantics,Computers / Mathematical & Statistical Software,Mathematics / Discrete Mathematics,Mathematics / Probability & Statistics / General,Mathematics / Probability & Statistics / Stochastic Processes,Science / Life Sciences / Biology,Science / Life Sciences / General},
  langid = {english},
  pagetotal = {545}
}
% == BibLateX quality report for hastieElementsStatisticalLearning2013:
% ? Title looks like it was stored in title-case in Zotero

@article{hedinOverviewTREC2009,
  ids = {hedinOverviewTREC2009a},
  title = {Overview of the {{TREC}} 2009 {{Legal Track}}},
  author = {Hedin, Bruce and Tomlinson, Stephen and Baron, Jason R and Oard, Douglas W},
  date = {2009},
  pages = {40},
  abstract = {TREC 2009 was the fourth year of the Legal Track, which focuses on evaluation of search technology for ``discovery'' (i.e., responsive review) of electronically stored information in litigation and regulatory settings. The track included two tasks: an Interactive task (in which real users could iteratively refine their queries and/or engage in multi-pass relevance feedback) and a Batch task (two-pass search in a controlled setting with some relevant and nonrelevant documents manually marked after the first pass). This paper describes the design of the two tasks and presents the results.},
  file = {/home/architect/Zotero/storage/AQYP6WZH/Hedin et al. - Overview of the TREC 2009 Legal Track.pdf;/home/architect/Zotero/storage/UYR7S5ZY/Hedin et al. - Overview of the TREC 2009 Legal Track.pdf},
  keywords = {No DOI found},
  langid = {english}
}
% == BibLateX quality report for hedinOverviewTREC2009:
% Missing required field 'journaltitle'
% ? Title looks like it was stored in title-case in Zotero

@software{IBMOpenapivalidator2020,
  title = {{{IBM}}/Openapi-Validator},
  date = {2020-03-23T09:54:19Z},
  origdate = {2018-10-15T19:59:22Z},
  url = {https://github.com/IBM/openapi-validator},
  urldate = {2020-04-03},
  abstract = {Configurable and extensible validator/linter for OpenAPI documents},
  organization = {{International Business Machines}}
}
% == BibLateX quality report for IBMOpenapivalidator2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@report{informationcommissionersofficePersonalInformationSection,
  title = {Personal Information (Section 40 and Regulation 13): {{Freedom}} of {{Information Act Environmental}} Information {{Regulations}}},
  shorttitle = {Personal Information},
  author = {{Information Commissioner's Office}},
  pages = {48},
  url = {https://ico.org.uk/media/for-organisations/documents/1213/personal-information-section-40-regulation-13.pdf},
  file = {/home/architect/Zotero/storage/Q3N44HTZ/Information Commissioner's Office - Personal information (section 40 and regulation 13.pdf},
  langid = {english},
  number = {20190925 v2.3}
}
% == BibLateX quality report for informationcommissionersofficePersonalInformationSection:
% Exactly one of 'date' / 'year' must be present
% Missing required field 'type'
% Missing required field 'institution'

@report{intelligenceReportSenateSelect2014,
  title = {Report of the {{Senate Select Committee}} on {{Intelligence Committee Study}} of the {{Central Intelligence Agency}}'s {{Detention}} and {{Interrogation Program}}, {{Together}} with {{Foreword}} by {{Chairman Feinstein}} and {{Additional}} and {{Minority Views}}},
  shorttitle = {Report of the {{Senate Select Committee}} on {{Intelligence Committee Study}} of the {{CIA}}'s {{Detention}} and {{Interrogation Program}}},
  author = {family=Intelligence, given=United States Congress Senate Select Committee, prefix=on, useprefix=false and Feinstein, Dianne},
  date = {2014},
  pages = {712},
  institution = {{United States Senate}},
  url = {https://www.intelligence.senate.gov/sites/default/files/publications/CRPT-113srpt288.pdf},
  file = {/home/architect/Zotero/storage/HZGMFC7V/Intelligence and Feinstein - 2014 - Report of the Senate Select Committee on Intellige.pdf},
  isbn = {978-0-16-092655-6},
  langid = {english},
  number = {113\textendash{}288}
}
% == BibLateX quality report for intelligenceReportSenateSelect2014:
% Unexpected field 'isbn'
% Missing required field 'type'
% ? Title looks like it was stored in title-case in Zotero

@video{InterpretableMachineLearning,
  title = {Interpretable {{Machine Learning Using LIME Framework}} - {{Kasia Kulma}} ({{PhD}}), {{Data Scientist}}, {{Aviva}}},
  url = {https://www.youtube.com/watch?v=CY3t11vuuOM},
  urldate = {2020-01-20},
  abstract = {This presentation was filmed at the London Artificial Intelligence \&amp; Deep Learning Meetup: https://www.meetup.com/London-Artific....

Enjoy the slides: https://www.slideshare.net/0xdata/int.... 

- - - 

Kasia discussed complexities of interpreting black-box algorithms and how these may affect some industries. She presented the most popular methods of interpreting Machine Learning classifiers, for example, feature importance or partial dependence plots and Bayesian networks. Finally, she introduced Local Interpretable Model-Agnostic Explanations (LIME) framework for explaining predictions of black-box learners \textendash{} including text- and image-based models - using breast cancer data as a specific case scenario.

Kasia Kulma is a Data Scientist at Aviva with a soft spot for R. She obtained a PhD (Uppsala University, Sweden) in evolutionary biology in 2013 and has been working on all things data ever since. For example, she has built recommender systems, customer segmentations, predictive models and now she is leading an NLP project at the UK's leading insurer. In spare time she tries to relax by hiking \&amp; camping, but if that doesn't work ;) she co-organizes R-Ladies meetups and writes a data science blog R-tastic (https://kkulma.github.io/).

https://www.linkedin.com/in/kasia-kul...},
  keywords = {\#nosource}
}
% == BibLateX quality report for InterpretableMachineLearning:
% Unexpected field 'title'
% ? Title looks like it was stored in title-case in Zotero

@video{ItAlwaysSeems,
  title = {``{{It}} Always Seems Impossible until It Is Done'': {{Sensitivity Review}} and {{Digital Records}}'},
  shorttitle = {``{{It}} Always Seems Impossible until It Is Done''},
  url = {https://www.youtube.com/watch?reload=9&v=ncdbLdshheI},
  urldate = {2020-02-15},
  abstract = {Joint seminer: Archives \&amp; Society and Digital History seminar
Speaker: Anthea Seles , The National Archives
http://ihrdighist.blogs.sas.ac.uk/201... 

Abstract

``It always seems impossible until it is done'': Sensitivity Review and Digital Records' touches on the experiences and lessons learned at The National Archives on digital records sensitivity in order to enable the scalable and repeatable transfer of digital records, and user access, while protecting personal data and sensitive information from release. The presentation draws directly from the published research report The application of technology- assisted review to born-digital records transfer, Inquiries and beyond (February 2016) and will explore the software testing The National Archives carried out to try and develop a scalable approach to the appraisal and selection, and sensitivity review of large unstructured digital records collections. During the talk Dr. Seles will also endeavour to touch the impact these approaches have on the historical record and the strengths and weaknesses data analytic software can have on future digital historical research.

Bio

Dr. Anthea Seles is graduate of Masters of Archival Studies (MAS) programme at the University of British Columbia (Vancouver, British Columbia) and a recent doctoral graduate from the Department of Information Studies at the University College London. Her doctorate: The Transferability of Trusted Digital Repository Standards to an East African Context was awarded the 2016 Digital Preservation Coalition Award for Most Distinguished Student Work in Digital Preservation. Dr. Seles has worked in the field of archives and records management for over 10 years, during that time she worked for the International Records Management Trust. At the Trust she examined topics such as data integrity for open data, accountability and transparency and worked with organisations like the African Union Commission (Addis Ababa) and the International Criminal Courts (The Hague, Netherlands). She joined The National Archives in 2014 as the Digital Records and Transfer Manager. In her position she and her team oversee the transfer of government digital records transfers. As part of this process she advises on the capabilities of data analytics/eDiscovery software for the purposes of digital appraisal and selection and sensitivity review.

Dr. Seles has lectured and spoken extensively on digital preservation topics at international conferences, symposia and universities. Most recently she has presented on the topics of digital sensitivity review at the University of Glasgow (November 2016), and on the impact of digital records on historical research at King's College (December 2016). She has also written several papers on digital record-keeping in Africa, based on her experiences at the International Records Management Trust.}
}
% == BibLateX quality report for ItAlwaysSeems:
% Unexpected field 'title'

@software{jdkanderssonJdkanderssonOpenAlchemy2020,
  title = {Jdkandersson/{{OpenAlchemy}}},
  author = {{jdkandersson}},
  date = {2020-04-05T09:25:30Z},
  origdate = {2019-08-10T05:09:36Z},
  url = {https://github.com/jdkandersson/OpenAlchemy},
  urldate = {2020-04-06},
  abstract = {Define SQLAlchemy models using the OpenAPI specification.},
  keywords = {openapi,openapi-specification,openapi3,python,python3,sqlalchemy,sqlalchemy-models,sqlalchemy-python}
}
% == BibLateX quality report for jdkanderssonJdkanderssonOpenAlchemy2020:
% Unexpected field 'title'
% Unexpected field 'author'
% ? Title looks like it was stored in lower-case in Zotero

@article{jonesOAuthAuthorizationFramework2012,
  title = {The {{OAuth}} 2.0 {{Authorization Framework}}: {{Bearer Token Usage}}},
  shorttitle = {The {{OAuth}} 2.0 {{Authorization Framework}}},
  author = {Jones, M. and Hardt, D.},
  date = {2012},
  issn = {2070-1721},
  url = {https://www.rfc-editor.org/info/rfc6750},
  urldate = {2020-03-20},
  file = {/home/architect/Zotero/storage/IR3DAFE2/rfc6750.html},
  number = {RFC 6750}
}
% == BibLateX quality report for jonesOAuthAuthorizationFramework2012:
% Missing required field 'journaltitle'
% ? Title looks like it was stored in title-case in Zotero

@book{jordanUsabilityEvaluationIndustry1996,
  title = {Usability {{Evaluation In Industry}}},
  author = {Jordan, Patrick W. and Thomas, B. and McClelland, Ian Lyall and Weerdmeester, Bernard},
  date = {1996-06-11},
  publisher = {{CRC Press}},
  abstract = {This book provides a variety of answers in its description and discussion of new, sometimes radical approaches to `usability evaluation', now an increasingly common business tool. It contains new thinking of the subject of usability evaluation in industry. Contributions come from those involved in the practice of industry-based usability evaluation as well as those involved in related research activity. The chapters are derived from and developed from presentations and discussions at the invited international seminar `Usability Evaluation in Industry', and give a leading edge overview of current usability practice in industry - identifying those issues of concern and approaches to tackling these.Key Features:* Provides a comprehensive overview of current practice* International examples * Contains practical examples of ergonomics at work and gives clear ideas of what does and doesn't work under industrial constraints},
  eprint = {IfUsRmzAqvEC},
  eprinttype = {googlebooks},
  isbn = {978-0-7484-0460-5},
  keywords = {Business & Economics / Production & Operations Management,Technology & Engineering / Engineering (General),Technology & Engineering / Industrial Engineering,Technology & Engineering / Manufacturing,Technology & Engineering / Quality Control},
  langid = {english},
  pagetotal = {276}
}
% == BibLateX quality report for jordanUsabilityEvaluationIndustry1996:
% ? Title looks like it was stored in title-case in Zotero

@jurisdiction{judgeshanksCabinetOfficeICO2018,
  title = {Cabinet {{Office}} v {{ICO}} and {{Greenpeace}}},
  author = {{Judge Shanks}},
  date = {2018-11-07},
  institution = {{GENERAL REGULATORY CHAMBER}},
  url = {http://informationrights.decisions.tribunals.gov.uk/DBFiles/Decision/i2537/Cabinet%20Office%20EA.2018.0270%20(08.11.19).pdf},
  urldate = {2020-04-01},
  abstract = {Tribunal order the partialdisclosure of a report into the shale gas industry in the UK},
  file = {/home/architect/Zotero/storage/S9V5SF3G/Cabinet Office EA.2018.0270 (08.11.19).pdf},
  langid = {english},
  number = {EA/2018/0270}
}
% == BibLateX quality report for judgeshanksCabinetOfficeICO2018:
% Unexpected field 'title'
% Unexpected field 'author'
% Unexpected field 'institution'
% Unexpected field 'number'
% ? Title looks like it was stored in title-case in Zotero

@article{kesslerScattertextBrowserBasedTool2017,
  title = {Scattertext: A {{Browser}}-{{Based Tool}} for {{Visualizing}} How {{Corpora Differ}}},
  shorttitle = {Scattertext},
  author = {Kessler, Jason S.},
  date = {2017-04-20},
  url = {http://arxiv.org/abs/1703.00565},
  urldate = {2019-12-11},
  abstract = {Scattertext is an open source tool for visualizing linguistic variation between document categories in a language-independent way. The tool presents a scatterplot, where each axis corresponds to the rank-frequency a term occurs in a category of documents. Through a tie-breaking strategy, the tool is able to display thousands of visible term-representing points and find space to legibly label hundreds of them. Scattertext also lends itself to a query-based visualization of how the use of terms with similar embeddings differs between document categories, as well as a visualization for comparing the importance scores of bag-of-words features to univariate metrics.},
  archivePrefix = {arXiv},
  eprint = {1703.00565},
  eprinttype = {arxiv},
  file = {/home/architect/Zotero/storage/ZZIF9CD7/Kessler - 2017 - Scattertext a Browser-Based Tool for Visualizing .pdf;/home/architect/Zotero/storage/VJLK7ICL/1703.html},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval,No DOI found},
  primaryClass = {cs}
}
% == BibLateX quality report for kesslerScattertextBrowserBasedTool2017:
% Unexpected field 'archivePrefix'
% Unexpected field 'primaryClass'
% Missing required field 'journaltitle'

@software{KiwicomSchemathesis2020,
  title = {Kiwicom/Schemathesis},
  date = {2020-04-02T19:43:20Z},
  origdate = {2019-08-19T11:13:01Z},
  url = {https://github.com/kiwicom/schemathesis},
  urldate = {2020-04-03},
  abstract = {A tool that generates and runs test cases for Open API / Swagger based apps},
  keywords = {cli,hypothesis,openapi3,property-based-testing,pytest,swagger},
  organization = {{Kiwi.com}}
}
% == BibLateX quality report for KiwicomSchemathesis2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@inproceedings{korenExploitationOpenAPIDocumentation2018,
  title = {The {{Exploitation}} of {{OpenAPI Documentation}} for the {{Generation}} of {{Web Frontends}}},
  booktitle = {Companion {{Proceedings}} of the {{The Web Conference}} 2018},
  author = {Koren, Istv\'an and Klamma, Ralf},
  date = {2018-04-23},
  pages = {781--787},
  publisher = {{International World Wide Web Conferences Steering Committee}},
  location = {{Lyon, France}},
  doi = {10.1145/3184558.3188740},
  abstract = {New Internet-enabled devices and Web services are introduced on a daily basis. Documentation formats are available that describe their functionalities in terms of API endpoints and parameters. In particular, the OpenAPI specification has gained considerable influence over the last years. Web-based solutions exist that generate interactive OpenAPI documentation with HTML5 \& JavaScript. They allow developers to quickly get an understanding what the services and devices do and how they work. However, the generated user interfaces are far from real-world practices of designers and end users. We present an approach to overcome this gap, by using a model-driven methodology resulting in state-of-the-art responsive Web user interfaces. To this end, we use the Interaction Flow Modeling Language (IFML) as intermediary model specification to bring together APIs and frontends. Our implementation is based on open standards like Web Components and SVG. A screencast of our tool is available at https://youtu.be/KFOPmPShak4},
  file = {/home/architect/Zotero/storage/GWJDJEYR/Koren and Klamma - 2018 - The Exploitation of OpenAPI Documentation for the .pdf;/home/architect/Zotero/storage/IIKRIYR9/Koren and Klamma - 2018 - The Exploitation of OpenAPI Documentation for the .pdf},
  isbn = {978-1-4503-5640-4},
  keywords = {ifml,interaction design,openapi,web components},
  series = {{{WWW}} '18}
}
% == BibLateX quality report for korenExploitationOpenAPIDocumentation2018:
% ? Title looks like it was stored in title-case in Zotero

@software{krispel-samselJuliankrispelReacttextselectionpopover2020,
  title = {Juliankrispel/React-Text-Selection-Popover},
  author = {Krispel-Samsel, Julian},
  date = {2020-03-17T15:09:14Z},
  origdate = {2018-07-12T21:24:21Z},
  url = {https://github.com/juliankrispel/react-text-selection-popover},
  urldate = {2020-04-03},
  abstract = {Selection based Text UI made easy. Contribute to juliankrispel/react-text-selection-popover development by creating an account on GitHub.},
  keywords = {draft-js,react,rich-text-editor,text-editor,text-user-interface}
}
% == BibLateX quality report for krispel-samselJuliankrispelReacttextselectionpopover2020:
% Unexpected field 'title'
% Unexpected field 'author'
% ? Title looks like it was stored in lower-case in Zotero

@software{Kubernetes2020,
  title = {Kubernetes},
  date = {2020-03-31T09:35:54Z},
  origdate = {2014-06-06T22:56:04Z},
  url = {https://github.com/kubernetes/kubernetes},
  urldate = {2020-03-31},
  abstract = {Production-Grade Container Scheduling and Management},
  keywords = {cncf,containers,go,kubernetes},
  organization = {{Kubernetes}}
}
% == BibLateX quality report for Kubernetes2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@online{LeadDeveloppeurFront,
  title = {Lead D\'eveloppeur Front (React ou Vue.js) - L'Atelier - CDI \`a Paris},
  url = {https://www.welcometothejungle.com/fr/companies/l-atelier/jobs/lead-frontend-developpeur-vue-js_paris},
  urldate = {2020-04-03},
  abstract = {L'Atelier recrute un(e) Lead D\'eveloppeur Front (React ou Vue.js) \`a Paris !},
  file = {/home/architect/Zotero/storage/HR7AQKZK/lead-frontend-developpeur-vue-js_paris.html},
  langid = {french},
  note = {Library Catalog: www.welcometothejungle.com}
}
% == BibLateX quality report for LeadDeveloppeurFront:
% Exactly one of 'date' / 'year' must be present

@article{lemaitreImbalancedlearnPythonToolbox2017,
  ids = {lemaitreImbalancedlearnPythonToolbox2017a},
  title = {Imbalanced-Learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning},
  shorttitle = {Imbalanced-Learn},
  author = {Lema\^itre, Guillaume and Nogueira, Fernando and Aridas, Christos K.},
  date = {2017-01-01},
  journaltitle = {The Journal of Machine Learning Research},
  shortjournal = {J. Mach. Learn. Res.},
  volume = {18},
  pages = {559--563},
  issn = {1532-4435},
  abstract = {imbalanced-learn is an open-source python toolbox aiming at providing a wide range of methods to cope with the problem of imbalanced dataset frequently encountered in machine learning and pattern recognition. The implemented state-of-the-art methods can be categorized into 4 groups: (i) under-sampling, (ii) over-sampling, (iii) combination of over-and under-sampling, and (iv) ensemble learning methods. The proposed toolbox depends only on numpy, scipy, and scikit-learn and is distributed under MIT license. Furthermore, it is fully compatible with scikit-learn and is part of the scikit-learn-contrib supported project. Documentation, unit tests as well as integration tests are provided to ease usage and contribution. Source code, binaries, and documentation can be downloaded from https://github.com/scikit-learn-contrib/imbalanced-learn.},
  file = {/home/architect/Zotero/storage/4SL8ZLAR/LemaÃ®tre et al. - 2017 - Imbalanced-learn a python toolbox to tackle the c.pdf;/home/architect/Zotero/storage/I9VV6N9U/LemaÃ®tre et al. - 2017 - Imbalanced-learn a python toolbox to tackle the c.pdf},
  keywords = {ensemble learning,imbalanced dataset,machine learning,No DOI found,over-sampling,python,under-sampling},
  number = {1}
}

@patent{libinAutomaticProtectionPartial2019,
  title = {Automatic Protection of Partial Document Content},
  author = {Libin, Phil},
  date = {2019-08-08},
  url = {https://patents.google.com/patent/US20190243983A1/en},
  urldate = {2019-12-10},
  abstract = {Protecting a fragment of a document includes automatically detecting the fragment without user intervention based on the content of the fragment and/or the context of the fragment within a set of documents, selectively encrypting the fragment to prevent unauthorized access, and providing an alternative view of the fragment that prevents viewing and access of content corresponding to the fragment unless a decryption password is provided. Automatically detecting the fragment may include detecting numbers and alphanumeric sequences of sufficient length that do not represent commonly known abbreviations, detecting generic terms, detecting proper names, detecting terms signifying a type of content, detecting mutual location of terms and sensitive content, and/or detecting user defined terms. The generic terms may correspond to password, passcode, credentials, user name, account, ID, login, confidential, and/or sensitive. The proper names may be names of financial organizations and security organizations.},
  file = {/home/architect/Zotero/storage/MGPR2HT4/Libin - 2019 - Automatic protection of partial document content.pdf},
  holder = {{Evernote Corp}},
  keywords = {content,fragment,fragments,subset,user},
  number = {20190243983A1},
  type = {patentus}
}

@software{lundbergSlundbergShap2020,
  title = {Slundberg/Shap},
  author = {Lundberg, Scott},
  date = {2020-04-03T10:05:42Z},
  origdate = {2016-11-22T19:17:08Z},
  url = {https://github.com/slundberg/shap},
  urldate = {2020-04-03},
  abstract = {A game theoretic approach to explain the output of any machine learning model.},
  keywords = {deep-learning,explainability,gradient-boosting,interpretability,machine-learning,shap,shapley}
}
% == BibLateX quality report for lundbergSlundbergShap2020:
% Unexpected field 'title'
% Unexpected field 'author'
% ? Title looks like it was stored in lower-case in Zotero

@incollection{lundbergUnifiedApproachInterpreting2017,
  title = {A {{Unified Approach}} to {{Interpreting Model Predictions}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 30},
  author = {Lundberg, Scott M and Lee, Su-In},
  editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  date = {2017},
  pages = {4765--4774},
  publisher = {{Curran Associates, Inc.}},
  url = {http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf},
  urldate = {2020-02-24},
  file = {/home/architect/Zotero/storage/YEBHZISJ/Lundberg and Lee - A Unified Approach to Interpreting Model Predictio.pdf;/home/architect/Zotero/storage/YX933PYC/7062-a-unified-approach-to-interpreting-model-predicti.html}
}
% == BibLateX quality report for lundbergUnifiedApproachInterpreting2017:
% ? Title looks like it was stored in title-case in Zotero

@software{Lxc2020,
  title = {Lxc},
  date = {2020-03-31T09:34:22Z},
  origdate = {2012-09-07T18:50:27Z},
  url = {https://github.com/lxc/lxc},
  urldate = {2020-03-31},
  abstract = {LXC},
  keywords = {c,containers,lxc},
  organization = {{LXC - Linux Containers}}
}
% == BibLateX quality report for Lxc2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@article{martineauDeltaTFIDFImproved,
  title = {Delta {{TFIDF}}: {{An Improved Feature Space}} for {{Sentiment Analysis}}},
  author = {Martineau, Justin and Finin, Tim},
  pages = {4},
  abstract = {Mining opinions and sentiment from social networking sites is a popular application for social media systems. Common approaches use a machine learning system with a bag of words feature set. We present Delta TFIDF, an intuitive general purpose technique to efficiently weight word scores before classification. Delta TFIDF is easy to compute, implement, and understand. We use Support Vector Machines to show that Delta TFIDF significantly improves accuracy for sentiment analysis problems using three well known data sets.},
  file = {/home/architect/Zotero/storage/UAJTUXMP/Martineau and Finin - Delta TFIDF An Improved Feature Space for Sentime.pdf},
  keywords = {No DOI found},
  langid = {english}
}
% == BibLateX quality report for martineauDeltaTFIDFImproved:
% Exactly one of 'date' / 'year' must be present
% Missing required field 'journaltitle'
% ? Title looks like it was stored in title-case in Zotero

@online{MaterialDesign,
  title = {Material {{Design}}},
  date = {2020},
  url = {https://material.io/},
  urldate = {2020-03-27},
  abstract = {Material is an adaptable system of guidelines, components, and tools that support the best practices of user interface design. Backed by open-source code, Material streamlines collaboration between designers and developers, and helps teams quickly build beautiful products.},
  file = {/home/architect/Zotero/storage/S8HID4BT/design.html},
  langid = {english},
  note = {Library Catalog: material.io}
}
% == BibLateX quality report for MaterialDesign:
% ? Title looks like it was stored in title-case in Zotero

@software{Materialui2020,
  title = {Material-Ui},
  date = {2020},
  origdate = {2014-08-18T19:11:54Z},
  url = {https://github.com/mui-org/material-ui},
  urldate = {2020-03-20},
  abstract = {React components for faster and easier web development. Build your own design system, or start with Material Design.},
  keywords = {design-systems,javascript,material-design,react,react-components,typescript},
  organization = {{Material-UI}}
}
% == BibLateX quality report for Materialui2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@article{mattheyChutSigneHarpocrate2011,
  title = {``{{Chut}}!'' {{Le}} Signe d'{{Harpocrate}} et l'invitation Au Silence},
  author = {Matthey, Philippe},
  date = {2011}
}
% == BibLateX quality report for mattheyChutSigneHarpocrate2011:
% Missing required field 'journaltitle'

@online{mcateerRevolutionisingRedactionMy2019,
  title = {Revolutionising {{Redaction}}- {{My Final Year Project}}},
  author = {McAteer, Chloe},
  date = {2019-05-31T13:42:21.290Z},
  journaltitle = {Medium},
  url = {https://towardsdatascience.com/revolutionising-redaction-my-final-year-project-fe664e28ef84},
  urldate = {2020-03-26},
  abstract = {Now with major changes in regulations, it has become even more important that personal data is secured and only seen by the right people\ldots{}},
  file = {/home/architect/Zotero/storage/S6E5NJRB/revolutionising-redaction-my-final-year-project-fe664e28ef84.html},
  langid = {english},
  note = {Library Catalog: towardsdatascience.com}
}
% == BibLateX quality report for mcateerRevolutionisingRedactionMy2019:
% Unexpected field 'journaltitle'
% ? Title looks like it was stored in title-case in Zotero

@incollection{mcdonaldActiveLearningStrategies2018,
  title = {Active {{Learning Strategies}} for {{Technology Assisted Sensitivity Review}}},
  booktitle = {Advances in {{Information Retrieval}}},
  author = {McDonald, Graham and Macdonald, Craig and Ounis, Iadh},
  editor = {Pasi, Gabriella and Piwowarski, Benjamin and Azzopardi, Leif and Hanbury, Allan},
  date = {2018},
  volume = {10772},
  pages = {439--453},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-76941-7_33},
  abstract = {Government documents must be reviewed to identify and protect any sensitive information, such as personal information, before the documents can be released to the public. However, in the era of digital government documents, such as e-mail, traditional sensitivity review procedures are no longer practical, for example due to the volume of documents to be reviewed. Therefore, there is a need for new technology assisted review protocols to integrate automatic sensitivity classification into the sensitivity review process. Moreover, to effectively assist sensitivity review, such assistive technologies must incorporate reviewer feedback to enable sensitivity classifiers to quickly learn and adapt to the sensitivities within a collection, when the types of sensitivity are not known a priori. In this work, we present a thorough evaluation of active learning strategies for sensitivity review. Moreover, we present an active learning strategy that integrates reviewer feedback, from sensitive text annotations, to identify features of sensitivity that enable us to learn an effective sensitivity classifier (0.7 Balanced Accuracy) using significantly less reviewer effort, according to the sign test (p {$<$} 0.01). Moreover, this approach results in a 51\% reduction in the number of documents required to be reviewed to achieve the same level of classification accuracy, compared to when the approach is deployed without annotation features.},
  file = {/home/architect/Zotero/storage/VI8KFINW/McDonald et al. - 2018 - Active Learning Strategies for Technology Assisted.pdf},
  isbn = {978-3-319-76940-0 978-3-319-76941-7},
  langid = {english}
}
% == BibLateX quality report for mcdonaldActiveLearningStrategies2018:
% 'isbn': not a valid ISBN
% ? Title looks like it was stored in title-case in Zotero

@incollection{mcdonaldClassifierDigitalSensitivity2014,
  title = {Towards a {{Classifier}} for {{Digital Sensitivity Review}}},
  booktitle = {Advances in {{Information Retrieval}}},
  author = {McDonald, Graham and Macdonald, Craig and Ounis, Iadh and Gollins, Timothy},
  editor = {family=Rijke, given=Maarten, prefix=de, useprefix=true and Kenter, Tom and family=Vries, given=Arjen P., prefix=de, useprefix=true and Zhai, ChengXiang and family=Jong, given=Franciska, prefix=de, useprefix=true and Radinsky, Kira and Hofmann, Katja},
  date = {2014},
  volume = {8416},
  pages = {500--506},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-06028-6_48},
  abstract = {The sensitivity review of government records is essential before they can be released to the official government archives, to prevent sensitive information (such as personal information, or that which is prejudicial to international relations) from being released. As records are typically reviewed and released after a period of decades, sensitivity review practices are still based on paper records. The transition to digital records brings new challenges, e.g. increased volume of digital records, making current practices impractical to use. In this paper, we describe our current work towards developing a sensitivity review classifier that can identify and prioritise potentially sensitive digital records for review. Using a test collection built from government records with real sensitivities identified by government assessors, we show that considering the entities present in each record can markedly improve upon a text classification baseline.},
  file = {/home/architect/Zotero/storage/DMFTFMRW/McDonald et al. - 2014 - Towards a Classifier for Digital Sensitivity Revie.pdf},
  isbn = {978-3-319-06027-9 978-3-319-06028-6},
  langid = {english}
}
% == BibLateX quality report for mcdonaldClassifierDigitalSensitivity2014:
% 'isbn': not a valid ISBN
% ? Title looks like it was stored in title-case in Zotero

@incollection{mcdonaldEnhancingSensitivityClassification2017,
  title = {Enhancing {{Sensitivity Classification}} with {{Semantic Features Using Word Embeddings}}},
  booktitle = {Advances in {{Information Retrieval}}},
  author = {McDonald, Graham and Macdonald, Craig and Ounis, Iadh},
  editor = {Jose, Joemon M and Hauff, Claudia and Alt\i{}ngovde, Ismail Sengor and Song, Dawei and Albakour, Dyaa and Watt, Stuart and Tait, John},
  date = {2017},
  volume = {10193},
  pages = {450--463},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-56608-5_35},
  abstract = {Government documents must be reviewed to identify any sensitive information they may contain, before they can be released to the public. However, traditional paper-based sensitivity review processes are not practical for reviewing born-digital documents. Therefore, there is a timely need for automatic sensitivity classification techniques, to assist the digital sensitivity review process. However, sensitivity is typically a product of the relations between combinations of terms, such as who said what about whom, therefore, automatic sensitivity classification is a difficult task. Vector representations of terms, such as word embeddings, have been shown to be effective at encoding latent term features that preserve semantic relations between terms, which can also be beneficial to sensitivity classification. In this work, we present a thorough evaluation of the effectiveness of semantic word embedding features, along with term and grammatical features, for sensitivity classification. On a test collection of government documents containing real sensitivities, we show that extending text classification with semantic features and additional term n-grams results in significant improvements in classification effectiveness, correctly classifying 9.99\% more sensitive documents compared to the text classification baseline.},
  file = {/home/architect/Zotero/storage/F268VJKN/McDonald et al. - 2017 - Enhancing Sensitivity Classification with Semantic.pdf;/home/architect/Zotero/storage/MANDGDSJ/McDonald et al. - 2017 - Enhancing Sensitivity Classification with Semantic.pdf;/home/architect/Zotero/storage/MJEB7FER/McDonald et al. - 2017 - Enhancing Sensitivity Classification with Semantic.pdf;/home/architect/Zotero/storage/TBXGTEBF/McDonald et al. - 2017 - Enhancing Sensitivity Classification with Semantic.pdf;/home/architect/Zotero/storage/V4LF6YP3/McDonald et al. - 2017 - Enhancing Sensitivity Classification with Semantic.pdf},
  isbn = {978-3-319-56607-8 978-3-319-56608-5},
  langid = {english}
}
% == BibLateX quality report for mcdonaldEnhancingSensitivityClassification2017:
% 'isbn': not a valid ISBN
% ? Title looks like it was stored in title-case in Zotero

@article{mcdonaldFrameworkEnhancedText2015,
  title = {A {{Framework}} for {{Enhanced Text Classification}} in {{Sensitivity}} and {{Reputation Management}}},
  author = {McDonald, Graham S.},
  date = {2015-09-01},
  doi = {10.14236/ewic/fdia2015.15},
  file = {/home/architect/Zotero/storage/CHWYCCCJ/McDonald - 2015 - A Framework for Enhanced Text Classification in Se.pdf;/home/architect/Zotero/storage/KMIKY9BM/hosted-document.html}
}
% == BibLateX quality report for mcdonaldFrameworkEnhancedText2015:
% Missing required field 'journaltitle'
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{mcdonaldHowSensitivityClassification2019,
  ids = {mcdonaldHowSensitivityClassification2019a},
  title = {How {{Sensitivity Classification Effectiveness Impacts Reviewers}} in {{Technology}}-{{Assisted Sensitivity Review}}},
  booktitle = {Proceedings of the 2019 {{Conference}} on {{Human Information Interaction}} and {{Retrieval}}  - {{CHIIR}} '19},
  author = {McDonald, Graham and Macdonald, Craig and Ounis, Iadh},
  date = {2019},
  pages = {337--341},
  publisher = {{ACM Press}},
  location = {{Glasgow, Scotland UK}},
  doi = {10.1145/3295750.3298962},
  abstract = {All government documents that are released to the public must first be manually reviewed to identify and protect any sensitive information, e.g. confidential information. However, the unassisted manual sensitivity review of born-digital documents is not practical due to, for example, the volume of documents that are created. Previous work has shown that sensitivity classification can be effective for predicting if a document contains sensitive information. However, since all of the released documents must be manually reviewed, it is important to know if sensitivity classification can assist sensitivity reviewers in making their sensitivity judgements. Hence, in this paper, we conduct a digital sensitivity review user study, to investigate if the accuracy of sensitivity classification effects the number of documents that a reviewer correctly judges to be sensitive or not (reviewer accuracy) and the time that it takes to sensitivity review a document (reviewing speed). Our results show that providing reviewers with sensitivity classification predictions, from a classifier that achieves 0.7 Balanced Accuracy, results in a 38\% increase in mean reviewer accuracy and an increase of 72\% in mean reviewing speeds, compared to when reviewers are not provided with predictions. Overall, our findings demonstrate that sensitivity classification is a viable technology for assisting with the sensitivity review of born-digital government documents.},
  eventtitle = {The 2019 {{Conference}}},
  file = {/home/architect/Zotero/storage/7X4DPQMW/McDonald et al. - 2019 - How Sensitivity Classification Effectiveness Impac.pdf;/home/architect/Zotero/storage/8EQ6IW2A/McDonald et al. - 2019 - How Sensitivity Classification Effectiveness Impac.pdf;/home/architect/Zotero/storage/A6NAM552/McDonald et al. - 2019 - How Sensitivity Classification Effectiveness Impac.pdf},
  isbn = {978-1-4503-6025-8},
  keywords = {classification,digital sensitivity review,freedom of information,information retrieval,sensitivity classification,technology-assisted sensitivity review,user study},
  langid = {english}
}
% == BibLateX quality report for mcdonaldHowSensitivityClassification2019:
% ? Title looks like it was stored in title-case in Zotero

@incollection{mcdonaldMaximisingOpennessDigital2018,
  title = {Towards {{Maximising Openness}} in {{Digital Sensitivity Review Using Reviewing Time Predictions}}},
  booktitle = {Advances in {{Information Retrieval}}},
  author = {McDonald, Graham and Macdonald, Craig and Ounis, Iadh},
  editor = {Pasi, Gabriella and Piwowarski, Benjamin and Azzopardi, Leif and Hanbury, Allan},
  date = {2018},
  volume = {10772},
  pages = {699--706},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-76941-7_65},
  abstract = {The adoption of born-digital documents, such as email, by governments, such as in the UK and USA, has resulted in a large backlog of born-digital documents that must be sensitivity reviewed before they can be opened to the public, to ensure that no sensitive information is released, e.g. personal or confidential information. However, it is not practical to review all of the backlog with the available reviewing resources and, therefore, there is a need for automatic techniques to increase the number of documents that can be opened within a fixed reviewing time budget. In this paper, we conduct a user study and use the log data to build models to predict reviewing times for an average sensitivity reviewer. Moreover, we show that using our reviewing time predictions to select the order that documents are reviewed can markedly increase the ratio of reviewed documents that are released to the public, e.g. +30\% for collections with high levels of sensitivity, compared to reviewing by shortest document first. This, in turn, increases the total number of documents that are opened to the public within a fixed reviewing time budget, e.g. an extra 200 documents in 100 hours reviewing.},
  file = {/home/architect/Zotero/storage/XZBNW7KI/McDonald et al. - 2018 - Towards Maximising Openness in Digital Sensitivity.pdf},
  isbn = {978-3-319-76940-0 978-3-319-76941-7},
  langid = {english}
}
% == BibLateX quality report for mcdonaldMaximisingOpennessDigital2018:
% 'isbn': not a valid ISBN
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{mcdonaldStudySVMKernel2017,
  title = {A {{Study}} of {{SVM Kernel Functions}} for {{Sensitivity Classification Ensembles}} with {{POS Sequences}}},
  booktitle = {Proceedings of the 40th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}  - {{SIGIR}} '17},
  author = {McDonald, Graham and Garc\'ia-Pedrajas, Nicol\'as and Macdonald, Craig and Ounis, Iadh},
  date = {2017},
  pages = {1097--1100},
  publisher = {{ACM Press}},
  location = {{Shinjuku, Tokyo, Japan}},
  doi = {10.1145/3077136.3080731},
  abstract = {Freedom of Information (FOI) laws legislate that government documents should be opened to the public. However, many government documents contain sensitive information, such as con dential information, that is exempt from release. erefore, government documents must be sensitivity reviewed prior to release, to identify and close any sensitive information. With the adoption of born-digital documents, such as email, there is a need for automatic sensitivity classi cation to assist digital sensitivity review. SVM classi ers and Part-of-Speech sequences have separately been shown to be promising for sensitivity classi cation. However, sequence classi cation methodologies, and speci cally SVM kernel functions, have not been fully investigated for sensitivity classi cation. erefore, in this work, we present an evaluation of ve SVM kernel functions for sensitivity classi cation using POS sequences. Moreover, we show that an ensemble classi er that combines POS sequence classi cation with text classi cation can signi cantly improve sensitivity classi cation e ectiveness (+6.09\% F2) compared with a text classi cation baseline, according to McNemar's test of signi cance.},
  eventtitle = {The 40th {{International ACM SIGIR Conference}}},
  file = {/home/architect/Zotero/storage/Z6PEEIW4/McDonald et al. - 2017 - A Study of SVM Kernel Functions for Sensitivity Cl.pdf},
  isbn = {978-1-4503-5022-8},
  langid = {english}
}
% == BibLateX quality report for mcdonaldStudySVMKernel2017:
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{mcdonaldUsingPartofSpeechNgrams2015,
  title = {Using {{Part}}-of-{{Speech N}}-Grams for {{Sensitive}}-{{Text Classification}}},
  booktitle = {Proceedings of the 2015 {{International Conference}} on {{Theory}} of {{Information Retrieval}} - {{ICTIR}} '15},
  author = {McDonald, Graham and Macdonald, Craig and Ounis, Iadh},
  date = {2015},
  pages = {381--384},
  publisher = {{ACM Press}},
  location = {{Northampton, Massachusetts, USA}},
  doi = {10.1145/2808194.2809496},
  abstract = {Freedom of Information legislations in many western democracies, including the United Kingdom (UK) and the United States of America (USA), state that citizens have typically the right to access government documents. However, certain sensitive information is exempt from release into the public domain. For example, in the UK, FOIA Exemption 27 (International Relations) excludes the release of Information that might damage the interests of the UK abroad. Therefore, the process of reviewing government documents for sensitivity is essential to determine if a document must be redacted before it is archived, or closed until the information is no longer sensitive. With the increased volume of digital government documents in recent years, there is a need for new tools to assist the digital sensitivity review process. Therefore, in this paper we propose an automatic approach for identifying sensitive text in documents by measuring the amount of sensitivity in sequences of text. Using government documents reviewed by trained sensitivity reviewers, we focus on an aspect of FOIA Exemption 27 which can have a major impact on international relations, namely information supplied in confidence. We show that our approach leads to markedly increased recall of sensitive text, while achieving a very high level of precision, when compared to a baseline that has been shown to be effective at identifying sensitive text in other domains.},
  eventtitle = {The 2015 {{International Conference}}},
  file = {/home/architect/Zotero/storage/44RDC47A/McDonald et al. - 2015 - Using Part-of-Speech N-grams for Sensitive-Text Cl.pdf;/home/architect/Zotero/storage/5FVAS2SY/McDonald et al. - 2015 - Using Part-of-Speech N-grams for Sensitive-Text Cl.pdf;/home/architect/Zotero/storage/7G8Q8PPS/McDonald et al. - 2015 - Using Part-of-Speech N-grams for Sensitive-Text Cl.pdf},
  isbn = {978-1-4503-3833-2},
  langid = {english}
}

@software{MicrosoftVscode2020,
  title = {Microsoft/Vscode},
  date = {2020-03-27T10:39:06Z},
  origdate = {2015-09-03T20:23:38Z},
  url = {https://github.com/microsoft/vscode},
  urldate = {2020-03-27},
  abstract = {Visual Studio Code. Contribute to microsoft/vscode development by creating an account on GitHub.},
  keywords = {editor,electron,microsoft,typescript,visual-studio-code},
  organization = {{Microsoft}}
}
% == BibLateX quality report for MicrosoftVscode2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@software{MongoDB2020,
  title = {{{MongoDB}}},
  date = {2020-03-31T08:35:43Z},
  origdate = {2009-01-15T16:15:18Z},
  url = {https://github.com/mongodb/mongo},
  urldate = {2020-03-31},
  abstract = {The MongoDB Database. Contribute to mongodb/mongo development by creating an account on GitHub.},
  keywords = {c-plus-plus,database,mongodb,nosql},
  organization = {{mongodb}}
}
% == BibLateX quality report for MongoDB2020:
% Unexpected field 'title'
% Unexpected field 'organization'

@article{mooreBloodTransfusionIndependent1997,
  title = {Blood {{Transfusion}}: {{An Independent Risk Factor}} for {{Postinjury Multiple Organ Failure}}},
  shorttitle = {Blood {{Transfusion}}},
  author = {Moore, Frederick A. and Moore, Ernest E. and Sauaia, Angela},
  date = {1997-06-01},
  journaltitle = {Archives of Surgery},
  shortjournal = {Arch Surg},
  volume = {132},
  pages = {620--625},
  issn = {0004-0010},
  doi = {10.1001/archsurg.1997.01430300062013},
  abstract = {{$<$}h3{$>$}Objective:{$<$}/h3{$><$}p{$>$}To determine if blood transfusion is a consistent risk factor for postinjury multiple organ failure (MOF), independent of other shock indexes.{$<$}/p{$><$}h3{$>$}Design:{$<$}/h3{$><$}p{$>$}A 55-month inception cohort study ending on August 30, 1995. Data characterizing postinjury MOF were prospectively collected. Multiple logistic regression analysis was performed on 5 sets of data. Set 1 included admission data (age, sex, comorbidity, injury mechanism, Glasgow Coma Scale, Injury Severity Score, and systolic blood pressure determined in the emergency department) plus the amount of blood transfused within the first 12 hours. In the subsequent 4 data sets, other indexes of shock (early base deficit, early lactate level, late base deficit, and late lactate level) were sequentially added. Additionally, the same multiple logistic regression analyses were performed with early MOF and late MOF as the outcome variables.{$<$}/p{$><$}h3{$>$}Setting:{$<$}/h3{$><$}p{$>$}Denver General Hospital, Denver, Colo, is a regional level I trauma center.{$<$}/p{$><$}h3{$>$}Patients:{$<$}/h3{$><$}p{$>$}Five hundred thirteen consecutive trauma patients admitted to the trauma intensive care unit with an Injury Severity Score greater than 15 who were older than 16 years and who survived longer than 48 hours.{$<$}/p{$><$}h3{$>$}Interventions:{$<$}/h3{$><$}p{$>$}None.{$<$}/p{$><$}h3{$>$}Main Outcome Measures:{$<$}/h3{$><$}p{$>$}The relationship of blood transfusions and other shock indexes with the outcome variable, MOF.{$<$}/p{$><$}h3{$>$}Results:{$<$}/h3{$><$}p{$>$}A dose-response relationship between early blood transfusion and the later development of MOF was identified. Despite the inclusion of other indexes of shock, blood transfusion was identified as an independent risk factor in 13 of the 15 multiple logistic regression models tested; the odds ratios were high, especially in the early MOF models.{$<$}/p{$><$}h3{$>$}Conclusion:{$<$}/h3{$><$}p{$>$}Blood transfusion is an early consistent risk factor for postinjury MOF, independent of other indexes of shock.{$<$}/p{$><$}p{$>$}Arch Surg. 1997;132:620-625{$<$}/p{$>$}},
  file = {/home/architect/Zotero/storage/57HN7X87/596854.html},
  langid = {english},
  number = {6}
}
% == BibLateX quality report for mooreBloodTransfusionIndependent1997:
% ? Title looks like it was stored in title-case in Zotero

@unpublished{mooreDistrolessDockerContainerizing2017,
  title = {Distroless {{Docker}}: {{Containerizing Apps}}, Not {{VMs}}},
  shorttitle = {Distroless {{Docker}}},
  author = {Moore, Matthew},
  date = {2017},
  url = {https://www.youtube.com/watch?v=lviLZFciDv4},
  urldate = {2020-02-08},
  eventtitle = {{{swampUP Sessions}}}
}

@mvbook{muellerReportInvestigationRussian2019,
  title = {Report on the Investigation into {{Russian}} Interference in the 2016 Presidential Election},
  shorttitle = {Mueller {{Report}}},
  author = {Mueller, Robert S.},
  date = {2019-03},
  volume = {I \& II},
  publisher = {{US Department of Justice}},
  location = {{Washington, DC}},
  url = {https://relayto.com/cdn/media/files/6hE5LFPORw2TKnEf8TkK_mueller-report (2).pdf},
  urldate = {2020-01-04},
  file = {/home/architect/Zotero/storage/6JHDIR9I/Report On The Investigation Into Russian Interfere.pdf},
  langid = {english},
  pagetotal = {593},
  volumes = {2}
}

@software{NGINX2020,
  title = {{{NGINX}}},
  date = {2020-03-31T04:59:03Z},
  origdate = {2015-06-23T10:26:27Z},
  url = {https://github.com/nginx/nginx},
  urldate = {2020-03-31},
  abstract = {An official read-only mirror of http://hg.nginx.org/nginx/ which is updated hourly. Pull requests on GitHub cannot be accepted and will be automatically closed. The proper way to submit changes to ...},
  organization = {{nginx}}
}
% == BibLateX quality report for NGINX2020:
% Unexpected field 'title'
% Unexpected field 'organization'

@software{OAIOpenAPISpecification2020,
  title = {{{OAI}}/{{OpenAPI}}-{{Specification}}},
  date = {2020-03-16T13:54:16Z},
  origdate = {2014-03-03T16:53:36Z},
  url = {https://github.com/OAI/OpenAPI-Specification},
  urldate = {2020-03-16},
  abstract = {The OpenAPI Specification Repository. Contribute to OAI/OpenAPI-Specification development by creating an account on GitHub.},
  keywords = {apis,oas,openapi,openapi-specification,rest,webapi},
  organization = {{OpenAPI Initiative}}
}
% == BibLateX quality report for OAIOpenAPISpecification2020:
% Unexpected field 'title'
% Unexpected field 'organization'

@inproceedings{ogdenDocumentThumbnailVisualizations1998,
  title = {Document Thumbnail Visualizations for Rapid Relevance Judgments: {{When}} Do They Pay Off?},
  shorttitle = {Document Thumbnail Visualizations for Rapid Relevance Judgments},
  booktitle = {The {{Seventh Text REtrieval Conference}} ({{TREC7}}). {{NIST}}},
  author = {Ogden, William and Davis, Mark and Rice, Sean},
  date = {1998},
  pages = {528--534},
  abstract = {this document retrieved?" Alternatively, the unique document viewer could have led to the superior performance. A fisheye view presents the area of current interest in normal scale but as distance from the interest area increases, information scale decreases. In Kaugar's document viewer, there could be multiple areas of interest, each defined by the presence of a search term in a sentence. These areas would be displayed in a normal font. Other sentences and paragraphs were shown in a smaller font. This allowed the user to very easily find and read relevant passages while ignoring intervening and mostly irrelevant text. Users could define new areas of interest in the document with a mouse click thereby returning those areas to a normal sized font. Because the documents were much smaller in size than the normal full sized scrolled view, much more of the relevant text fit within a single window on the computer screen perhaps making it easier to make relevance judgements.  Page 2},
  file = {/home/architect/Zotero/storage/QJWB5AK4/Ogden et al. - 1998 - Document thumbnail visualizations for rapid releva.pdf;/home/architect/Zotero/storage/Z55PSNG8/summary.html},
  keywords = {No DOI found}
}
% == BibLateX quality report for ogdenDocumentThumbnailVisualizations1998:
% ? Unsure about the formatting of the booktitle

@inproceedings{ogdenImprovingCrosslanguageText2000,
  title = {Improving Cross-Language Text Retrieval with Human Interactions},
  booktitle = {Proceedings of the 33rd {{Annual Hawaii International Conference}} on {{System Sciences}}},
  author = {Ogden, W.C. and Davis, M.W.},
  date = {2000-01},
  pages = {9 pp.-},
  issn = {null},
  doi = {10.1109/hicss.2000.926726},
  abstract = {Can we expect people to be able to get information from texts in languages they cannot read? We review two relevant lines of research bearing on this question and show how our results are being used in the design of a new Web interface for cross-language text retrieval. One line of research, "interactive IR", is concerned with the user interface issues for information retrieval systems such as how best to display the results of a text search. We review our current research, on "document thumbnail" visualizations, and discuss current Web conventions, practices and folklore. The other area of research, "Cross-Language Text Retrieval", is concerned with the design of automatic techniques, including Machine Translation, to retrieve texts in languages other than the language of the query. We review work we have done concerning query translation and multilingual text summarization. We then describe how these results are being applied and extended in the design a new demonstration interface, Keizai, an end-to-end, Web-based, cross-language text retrieval system. Beginning with an English query, the system will search Japanese and Korean Web data and display English summaries of the top ranking documents. A user should be able to accurately judge which foreign language documents are relevant to their information need and glean necessary information from the translation to schedule specific documents for human translation and subsequent analysis.},
  eventtitle = {Proceedings of the 33rd {{Annual Hawaii International Conference}} on {{System Sciences}}},
  file = {/home/architect/Zotero/storage/PJ4II4VV/Ogden and Davis - 2000 - Improving cross-language text retrieval with human.pdf;/home/architect/Zotero/storage/7SVNAIJD/improving-crosslanguage-text-retrieval-with-human-interactions.html;/home/architect/Zotero/storage/W3T5KT6E/926726.html},
  keywords = {cross-language text retrieval,Dictionaries,Displays,document thumbnail visualizations,end-to-end Web-based cross-language text retrieval system,foreign language documents,human interactions,Humans,Identity-based encryption,Information retrieval,information retrieval systems,Keizai,language translation,multilingual text summarization,Natural languages,Prototypes,query translation,Read only memory,search engines,text analysis,User interfaces,Visualization,Web interface}
}
% == BibLateX quality report for ogdenImprovingCrosslanguageText2000:
% Unexpected field 'issn'
% 'issn': not a valid ISSN

@inproceedings{olivaUnderstandingSensitivityFirst2020,
  title = {Understanding {{Sensitivity}}: A {{First Step Towards Automating Sensitivity Review}}},
  shorttitle = {Understanding {{Sensitivity}}},
  author = {Oliva, Rebecca and Kim, Yunhyong},
  date = {2020},
  location = {{London, UK}},
  url = {https://eprints.gla.ac.uk/193900/},
  urldate = {2020-02-16},
  abstract = {Memory institutions face new challenges associated with curating data heritage in relation to ``technological requirements for specialist skills, hardware, and software to render digital objects'' (Harvey citation). In particular, it is generally accepted that manual approaches to processing digital records are becoming intractable, due to the volume of digital records stored by organisations (McDonald, Macdonald, and Ounis 2015).

Sensitivity review is one of the necessary processes by which archivists determine which records may be released to the public, redacted, or closed to the public. This paper will discuss the complex nature of sensitivity review, for example in relation to legal mandates, controversial subjects, and cultural differences, to present the many factors that influence archivists in the sensitivity review process. Keeping a record open when it contains sensitive information can mean that memory institutions are breaking the law (Sloyan 2016), but a risk-averse approach such as restricting access to records that have not yet been reviewed may result in reduced levels of service for users and obscure subtle cultural dynamics involved in sensitivity.

Lacking scalable approaches to tackle the complexity of sensitivity review and to mitigate such risks impedes archivists as they work to balance their responsibility to provide access to our data heritage with their duty to redact or close records that are sensitive. Some of these challenges could be addressed by incorporating automated or technology-assisted approaches.

This paper will propose a nuanced understanding of sensitivity within archives and demonstrate that sensitive data is characterised by its context as much as its content, opening up a discussion regarding the potential of machine learning, information retrieval and natural language processing techniques in developing scalable technology-assisted sensitivity review workflows.},
  eventtitle = {Archives, {{Access}} and {{AI}}: {{Working}} with {{Born}}-{{Digital}} and {{Digitised Archival Collections}}},
  file = {/home/architect/Zotero/storage/JZMXX44P/Oliva and Kim - 2020 - Understanding Sensitivity a First Step Towards Au.pdf;/home/architect/Zotero/storage/EG7SSRFP/193900.html},
  keywords = {No DOI found},
  langid = {british}
}
% == BibLateX quality report for olivaUnderstandingSensitivityFirst2020:
% Missing required field 'booktitle'

@video{oliverGovernmentSurveillanceLast2015,
  title = {Government {{Surveillance}}: {{Last Week Tonight}} with {{John Oliver}}},
  shorttitle = {Government {{Surveillance}}},
  date = {2015-04-05},
  publisher = {{HBO}},
  url = {https://www.youtube.com/watch?v=XEVlyP4_11M},
  urldate = {2020-04-04},
  abstract = {There are very few government checks on what America's sweeping surveillance programs are capable of doing. John Oliver sits down with Edward Snowden to discuss the NSA, the balance between privacy and security, and dick-pics.

Connect with Last Week Tonight online...
Subscribe to the Last Week Tonight YouTube channel for more almost news as it almost happens: www.youtube.com/user/LastWeekTonight

Find Last Week Tonight on Facebook like your mom would:
http://Facebook.com/LastWeekTonight

Follow us on Twitter for news about jokes and jokes about news:
http://Twitter.com/LastWeekTonight

Visit our official site for all that other stuff at once:
http://www.hbo.com/lastweektonight
Connect with Last Week Tonight online...
Subscribe to the Last Week Tonight YouTube channel for more almost news as it almost happens: www.youtube.com/user/LastWeekTonight

Find Last Week Tonight on Facebook like your mom would:
http://Facebook.com/LastWeekTonight

Follow us on Twitter for news about jokes and jokes about news:
http://Twitter.com/LastWeekTonight

Visit our official site for all that other stuff at once:
http://www.hbo.com/lastweektonight},
  editora = {Oliver, John},
  editoratype = {collaborator},
  langid = {english},
  series = {Last {{Week Tonight}} with {{John Oliver}}}
}
% == BibLateX quality report for oliverGovernmentSurveillanceLast2015:
% Unexpected field 'title'
% Unexpected field 'publisher'
% Unexpected field 'editora'
% Unexpected field 'editoratype'
% Unexpected field 'series'
% ? Title looks like it was stored in title-case in Zotero

@software{OpenAPIToolsOpenapigenerator2020,
  title = {{{OpenAPITools}}/Openapi-Generator},
  date = {2020-03-16T13:07:11Z},
  origdate = {2018-05-12T09:57:56Z},
  url = {https://github.com/OpenAPITools/openapi-generator},
  urldate = {2020-03-16},
  abstract = {OpenAPI Generator allows generation of API client libraries (SDK generation), server stubs, documentation and configuration automatically given an OpenAPI Spec (v2, v3)},
  keywords = {api,api-client,api-server,generator,openapi,openapi-generator,openapi3,rest,rest-api,rest-client,restful-api,sdk},
  organization = {{OpenAPI Tools}}
}
% == BibLateX quality report for OpenAPIToolsOpenapigenerator2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@software{ParcelbundlerParcel2020,
  title = {Parcel-Bundler/Parcel},
  date = {2020-04-03T08:52:24Z},
  origdate = {2017-08-07T16:36:47Z},
  url = {https://github.com/parcel-bundler/parcel},
  urldate = {2020-04-03},
  abstract = {ðŸ“¦ðŸš€ Blazing fast, zero configuration web application bundler},
  keywords = {assets,build-tool,commonjs,compiler,css,es6,html,javascript,module-bundler,modules,web},
  organization = {{Parcel}}
}
% == BibLateX quality report for ParcelbundlerParcel2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@article{pedregosaScikitlearnMachineLearning2011,
  title = {Scikit-Learn: {{Machine Learning}} in {{Python}}},
  shorttitle = {Scikit-Learn},
  author = {Pedregosa, Fabian and Varoquaux, Ga\"el and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, \'Edouard},
  date = {2011},
  journaltitle = {Journal of Machine Learning Research},
  shortjournal = {J. Mach. Learn. Res.},
  volume = {12},
  pages = {2825--2830},
  issn = {ISSN 1533-7928},
  url = {http://www.jmlr.org/papers/v12/pedregosa11a},
  urldate = {2020-02-24},
  file = {/home/architect/Zotero/storage/ZEHTDPA3/Pedregosa et al. - 2011 - Scikit-learn Machine Learning in Python.pdf;/home/architect/Zotero/storage/R7MGB93H/pedregosa11a.html},
  issue = {Oct},
  keywords = {No DOI found}
}
% == BibLateX quality report for pedregosaScikitlearnMachineLearning2011:
% 'issn': not a valid ISSN

@inproceedings{plattProbabilisticOutputsSupport1999,
  title = {Probabilistic {{Outputs}} for {{Support Vector Machines}} and {{Comparisons}} to {{Regularized Likelihood Methods}}},
  booktitle = {Advances in {{Large Margin Classifiers}}},
  author = {Platt, John C.},
  date = {1999},
  pages = {61--74},
  publisher = {{MIT Press}},
  abstract = {The output of a classifier should be a calibrated posterior probability to enable post-processing. Standard SVMs do not provide such probabilities. One method to create probabilities is to directly train a kernel classifier with a logit link function and a regularized maximum likelihood score. However, training with a maximum likelihood score will produce non-sparse kernel machines. Instead, we train an SVM, then train the parameters of an additional sigmoid function to map the SVM outputs into probabilities. This chapter compares classification error rate and likelihood scores for an SVM plus sigmoid versus a kernel method trained with a regularized likelihood error function. These methods are tested on three data-mining-style data sets. The SVM+sigmoid yields probabilities of comparable quality to the regularized maximum likelihood kernel method, while still retaining the sparseness of the SVM.},
  file = {/home/architect/Zotero/storage/JEWRW7Y5/Platt - 1999 - Probabilistic Outputs for Support Vector Machines .pdf;/home/architect/Zotero/storage/VNJ49SEL/summary.html},
  keywords = {No DOI found}
}
% == BibLateX quality report for plattProbabilisticOutputsSupport1999:
% ? Unsure about the formatting of the booktitle
% ? Title looks like it was stored in title-case in Zotero

@software{Postgres2020,
  title = {Postgres},
  date = {2020-04-06T09:22:17Z},
  origdate = {2010-09-21T11:35:45Z},
  url = {https://github.com/postgres/postgres},
  urldate = {2020-04-06},
  abstract = {Mirror of the official PostgreSQL GIT repository. Note that this is just a *mirror*},
  organization = {{PostgreSQL}}
}
% == BibLateX quality report for Postgres2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@online{pstuffaCartesianFisheyeDistortion2019,
  title = {Cartesian {{Fisheye Distortion}}},
  author = {{pstuffa}},
  date = {2019-03-01},
  url = {https://observablehq.com/@pstuffa/cartesian-fisheye-distortion},
  urldate = {2019-12-10},
  abstract = {An Observable notebook by pstuffa.},
  file = {/home/architect/Zotero/storage/Z7RYRVKR/cartesian-fisheye-distortion.html},
  langid = {english}
}
% == BibLateX quality report for pstuffaCartesianFisheyeDistortion2019:
% ? Title looks like it was stored in title-case in Zotero

@legislation{PublicRecordsAct1958,
  title = {Public {{Records Act}}},
  date = {1958},
  pages = {32},
  url = {http://www.legislation.gov.uk/ukpga/Eliz2/6-7/51/data.pdf},
  file = {/home/architect/Zotero/storage/VMDQ76DG/1958 - Public Records Act 1958.pdf},
  langid = {english},
  number = {1958 CHAPTER 51 6 and 7 Eliz 2}
}
% == BibLateX quality report for PublicRecordsAct1958:
% Unexpected field 'title'
% Unexpected field 'pages'
% Unexpected field 'number'
% ? Title looks like it was stored in title-case in Zotero

@software{ReactPDFLibrary2020,
  title = {React {{PDF}} Library},
  date = {2020},
  url = {https://pdftron.com/documentation/web/react/},
  urldate = {2020-04-04},
  abstract = {World's \#1 PDF SDK Library for Web, Mobile, Server, Desktop},
  file = {/home/architect/Zotero/storage/SIPNKXXQ/react.html},
  note = {Library Catalog: www.pdftron.com},
  organization = {{PDFTron}}
}
% == BibLateX quality report for ReactPDFLibrary2020:
% Unexpected field 'title'
% Unexpected field 'note'
% Unexpected field 'organization'

@software{Recharts2020,
  title = {Recharts},
  date = {2020},
  origdate = {2015-08-07T06:50:27Z},
  url = {https://github.com/recharts/recharts},
  urldate = {2020-03-20},
  abstract = {Redefined chart library built with React and D3. Contribute to recharts/recharts development by creating an account on GitHub.},
  keywords = {charting-library,d3,react,recharts},
  organization = {{recharts}}
}
% == BibLateX quality report for Recharts2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@online{RedactedAIRemove,
  title = {Redacted {{AI}} - {{Remove}} Sensitive Information from Your {{PDF}} Documents},
  url = {https://redacted.ai/},
  urldate = {2020-03-09},
  file = {/home/architect/Zotero/storage/V6L7F4LA/redacted.ai.html}
}
% == BibLateX quality report for RedactedAIRemove:
% Exactly one of 'date' / 'year' must be present

@software{RedactedAIRemovea,
  title = {Redacted {{AI}} - {{Remove}} Sensitive Information from Your {{PDF}} Documents},
  shorttitle = {Redacted.Ai},
  date = {2020},
  location = {{Berkeley, Calif}},
  url = {https://redacted.ai/},
  urldate = {2020-03-27},
  file = {/home/architect/Zotero/storage/QCXUJYX4/-M3QMc3yPpOgNfof6JdX.html},
  organization = {{DocuVision LLC}}
}
% == BibLateX quality report for RedactedAIRemovea:
% Unexpected field 'title'
% Unexpected field 'location'
% Unexpected field 'organization'

@video{RedactedDemoVersion,
  title = {Redacted {{Demo Version}} 2},
  url = {https://www.youtube.com/watch?v=hLgwEs1KCdQ},
  urldate = {2020-03-26},
  abstract = {This is the latest version of the Redacted.ai demo. If you have any questions or feature requests please email info@redacted.ai}
}
% == BibLateX quality report for RedactedDemoVersion:
% Unexpected field 'title'
% ? Title looks like it was stored in title-case in Zotero

@software{Redux2020,
  title = {Redux},
  date = {2020-03-24T09:46:27Z},
  origdate = {2015-05-29T23:53:15Z},
  url = {https://github.com/reduxjs/redux},
  urldate = {2020-03-24},
  abstract = {Predictable state container for JavaScript apps. Contribute to reduxjs/redux development by creating an account on GitHub.},
  keywords = {redux},
  organization = {{Redux}}
}
% == BibLateX quality report for Redux2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@article{remusUncertainPromisePredictive2013,
  title = {The {{Uncertain Promise}} of {{Predictive Coding}}},
  author = {Remus, Dana A.},
  date = {2013/2014},
  journaltitle = {Iowa Law Review},
  shortjournal = {Iowa L. Rev.},
  volume = {99},
  pages = {1691--1724},
  url = {https://heinonline.org/HOL/P?h=hein.journals/ilr99&i=1743},
  urldate = {2020-03-15},
  file = {/home/architect/Zotero/storage/9Y7IEMMR/Remus - 2013 - The Uncertain Promise of Predictive Coding.pdf},
  langid = {english},
  number = {4}
}
% == BibLateX quality report for remusUncertainPromisePredictive2013:
% ? Title looks like it was stored in title-case in Zotero

@software{ribeiroMarcotcrLime2020,
  title = {Marcotcr/Lime},
  author = {Ribeiro, Marco Tulio Correia},
  date = {2020-04-03T09:25:05Z},
  origdate = {2016-03-15T22:18:10Z},
  url = {https://github.com/marcotcr/lime},
  urldate = {2020-04-03},
  abstract = {Lime: Explaining the predictions of any machine learning classifier}
}
% == BibLateX quality report for ribeiroMarcotcrLime2020:
% Unexpected field 'title'
% Unexpected field 'author'
% ? Title looks like it was stored in lower-case in Zotero

@inproceedings{ribeiroWhyShouldTrust2016,
  title = {"{{Why Should I Trust You}}?": {{Explaining}} the {{Predictions}} of {{Any Classifier}}},
  shorttitle = {"{{Why Should I Trust You}}?},
  booktitle = {Proceedings of the 22nd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  date = {2016-08-13},
  pages = {1135--1144},
  publisher = {{Association for Computing Machinery}},
  location = {{San Francisco, California, USA}},
  doi = {10.1145/2939672.2939778},
  abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
  file = {/home/architect/Zotero/storage/J2EC9Z6B/Ribeiro et al. - 2016 - Why Should I Trust You Explaining the Predicti.pdf;/home/architect/Zotero/storage/RGGJZU67/Ribeiro et al. - 2016 - Why Should I Trust You Explaining the Predicti.pdf},
  isbn = {978-1-4503-4232-2},
  keywords = {black box classifier,explaining machine learning,interpretability,interpretable machine learning},
  series = {{{KDD}} '16}
}
% == BibLateX quality report for ribeiroWhyShouldTrust2016:
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{robertsonDocumentLens1993,
  title = {The Document Lens},
  booktitle = {Proceedings of the 6th Annual {{ACM}} Symposium on {{User}} Interface Software and Technology  - {{UIST}} '93},
  author = {Robertson, George G. and Mackinlay, Jock D.},
  date = {1993},
  pages = {101--108},
  publisher = {{ACM Press}},
  location = {{Atlanta, Georgia, United States}},
  doi = {10.1145/168642.168652},
  eventtitle = {The 6th Annual {{ACM}} Symposium},
  file = {/home/architect/Zotero/storage/7FYRIBAX/Robertson and Mackinlay - 1993 - The document lens.pdf;/home/architect/Zotero/storage/HM8XY4AM/robertson1993.html},
  isbn = {978-0-89791-628-8},
  langid = {english}
}
% == BibLateX quality report for robertsonDocumentLens1993:
% ? Unsure about the formatting of the booktitle

@article{roitblatDocumentCategorizationLegal2010,
  title = {Document Categorization in Legal Electronic Discovery: Computer Classification vs. Manual Review},
  shorttitle = {Document Categorization in Legal Electronic Discovery},
  author = {Roitblat, Herbert L. and Kershaw, Anne and Oot, Patrick},
  date = {2010},
  journaltitle = {Journal of the American Society for Information Science and Technology},
  shortjournal = {J. Am. Soc. Inf. Sci. Technol.},
  volume = {61},
  pages = {70--80},
  issn = {1532-2890},
  doi = {10.1002/asi.21233},
  abstract = {In litigation in the US, the parties are obligated to produce to one another, when requested, those documents that are potentially relevant to issues and facts of the litigation (called ``discovery''). As the volume of electronic documents continues to grow, the expense of dealing with this obligation threatens to surpass the amounts at issue and the time to identify these relevant documents can delay a case for months or years. The same holds true for government investigations and third-parties served with subpoenas. As a result, litigants are looking for ways to reduce the time and expense of discovery. One approach is to supplant or reduce the traditional means of having people, usually attorneys, read each document, with automated procedures that use information retrieval and machine categorization to identify the relevant documents. This study compared an original categorization, obtained as part of a response to a Department of Justice Request and produced by having one or more of 225 attorneys review each document with automated categorization systems provided by two legal service providers. The goal was to determine whether the automated systems could categorize documents at least as well as human reviewers could, thereby saving time and expense. The results support the idea that machine categorization is no less accurate at identifying relevant/responsive documents than employing a team of reviewers. Based on these results, it would appear that using machine categorization can be a reasonable substitute for human review.},
  file = {/home/architect/Zotero/storage/J2H4ZP8W/Roitblat et al. - 2010 - Document categorization in legal electronic discov.pdf;/home/architect/Zotero/storage/YE9YX22H/Roitblat et al. - 2010 - Document categorization in legal electronic discov.pdf;/home/architect/Zotero/storage/RZQ6FVSL/asi.html},
  langid = {english},
  note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.21233},
  number = {1}
}

@software{romanRmnSklearndeltatfidf2019,
  title = {R-m-n/Sklearn-Deltatfidf},
  author = {Roman},
  date = {2019-12-01T12:30:22Z},
  origdate = {2017-02-12T09:39:55Z},
  url = {https://github.com/r-m-n/sklearn-deltatfidf},
  urldate = {2020-01-21},
  abstract = {DeltaTfidfVectorizer for scikit-learn. Contribute to r-m-n/sklearn-deltatfidf development by creating an account on GitHub.},
  keywords = {delta-tf-idf,python,scikit-learn,sentiment-analysis,sklearn,tf-idf}
}
% == BibLateX quality report for romanRmnSklearndeltatfidf2019:
% Unexpected field 'title'
% Unexpected field 'author'
% ? Title looks like it was stored in lower-case in Zotero

@incollection{sanchezDetectingSensitiveInformation2012,
  title = {Detecting {{Sensitive Information}} from {{Textual Documents}}: {{An Information}}-{{Theoretic Approach}}},
  shorttitle = {Detecting {{Sensitive Information}} from {{Textual Documents}}},
  booktitle = {Modeling {{Decisions}} for {{Artificial Intelligence}}},
  author = {S\'anchez, David and Batet, Montserrat and Viejo, Alexandre},
  editor = {Torra, Vicen{\c c} and Narukawa, Yasuo and L\'opez, Beatriz and Villaret, Mateu},
  date = {2012},
  volume = {7647},
  pages = {173--184},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-34620-0_17},
  abstract = {Whenever a document containing sensitive information needs to be made public, privacy-preserving measures should be implemented. Document sanitization aims at detecting sensitive pieces of information in text, which are removed or hidden prior publication. Even though methods detecting sensitive structured information like e-mails, dates or social security numbers, or domain specific data like disease names have been developed, the sanitization of raw textual data has been scarcely addressed. In this paper, we present a general-purpose method to automatically detect sensitive information from textual documents in a domain-independent way. Relying on the Information Theory and a corpus as large as the Web, it assess the degree of sensitiveness of terms according to the amount of information they provide. Preliminary results show that our method significantly improves the detection recall in comparison with approaches based on trained classifiers.},
  editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
  editorbtype = {redactor},
  file = {/home/architect/Zotero/storage/2R5WP6CJ/SÃ¡nchez et al. - 2012 - Detecting Sensitive Information from Textual Docum.pdf},
  isbn = {978-3-642-34619-4 978-3-642-34620-0},
  langid = {english}
}
% == BibLateX quality report for sanchezDetectingSensitiveInformation2012:
% 'isbn': not a valid ISBN
% ? Title looks like it was stored in title-case in Zotero

@article{sanchezSensitiveDocumentRelease2017,
  title = {Toward Sensitive Document Release with Privacy Guarantees},
  author = {S\'anchez, David and Batet, Montserrat},
  date = {2017-03-01},
  journaltitle = {Engineering Applications of Artificial Intelligence},
  shortjournal = {Engineering Applications of Artificial Intelligence},
  volume = {59},
  pages = {23--34},
  issn = {0952-1976},
  doi = {10.1016/j.engappai.2016.12.013},
  abstract = {Privacy has become a serious concern for modern Information Societies. The sensitive nature of much of the data that are daily exchanged or released to untrusted parties requires that responsible organizations undertake appropriate privacy protection measures. Nowadays, much of these data are texts (e.g., emails, messages posted in social media, healthcare outcomes, etc.) that, because of their unstructured and semantic nature, constitute a challenge for automatic data protection methods. In fact, textual documents are usually protected manually, in a process known as document redaction or sanitization. To do so, human experts identify sensitive terms (i.e., terms that may reveal identities and/or confidential information) and protect them accordingly (e.g., via removal or, preferably, generalization). To relieve experts from this burdensome task, in a previous work we introduced the theoretical basis of C-sanitization, an inherently semantic privacy model that provides the basis to the development of automatic document redaction/sanitization algorithms and offers clear and a priori privacy guarantees on data protection; even though its potential benefits C-sanitization still presents some limitations when applied to practice (mainly regarding flexibility, efficiency and accuracy). In this paper, we propose a new more flexible model, named (C, g(C))-sanitization, which enables an intuitive configuration of the trade-off between the desired level of protection (i.e., controlled information disclosure) and the preservation of the utility of the protected data (i.e., amount of semantics to be preserved). Moreover, we also present a set of technical solutions and algorithms that provide an efficient and scalable implementation of the model and improve its practical accuracy, as we also illustrate through empirical experiments.},
  file = {/home/architect/Zotero/storage/GNXKAXW4/SÃ¡nchez and Batet - 2017 - Toward sensitive document release with privacy gua.pdf;/home/architect/Zotero/storage/IFXU3JXF/S0952197616302408.html},
  keywords = {Document redaction,Ontologies,Privacy,Sanitization,Semantics},
  langid = {english}
}

@article{schneiderToolsMethodsProcessing2017,
  title = {Tools and {{Methods}} for {{Processing}} and {{Visualizing Large Corpora}}},
  author = {Schneider, Gerold and El-Assady, Mennatallah and Lehmann, Hans Martin},
  date = {2017},
  url = {https://kops.uni-konstanz.de/handle/123456789/45081},
  urldate = {2019-12-10},
  abstract = {We present several approaches and methods which we develop or use to create workflows from data to evidence. They start with looking for specific items in large corpora, exploring overuse of particular items, and using off-the-shelf visualization such as GoogleViz. Second, we present the advanced visualization tools and pipelines which the Visualization Group at University of Konstanz is developing. After an overview, we apply statistical visualizations, Lexical Episode Plots and Interactive Hierarchical Modeling to the vast historical linguistics data offered by the Corpus of Historical American English (COHA), which ranges from 1800 to 2000. We investigate on the one hand the increase of noun compounds and visually illustrate correlations in the data over time. On the other hand we compute and visualize trends and topics in society from 1800 to 2000. We apply an incremental topic modeling algorithm to the extracted compound nouns to detect thematic changes throughout the investigated time period of 200 years. In this paper, we utilize various tailored analysis and visualization approaches to gain insight into the data from different perspectives.},
  file = {/home/architect/Zotero/storage/DD9IE4UD/45081.html},
  keywords = {No DOI found},
  langid = {english}
}
% == BibLateX quality report for schneiderToolsMethodsProcessing2017:
% Missing required field 'journaltitle'
% ? Title looks like it was stored in title-case in Zotero

@software{ScikitlearncontribImbalancedlearn2020,
  title = {Imbalanced-Learn},
  date = {2020-03-27T14:00:37Z},
  origdate = {2014-08-16T05:08:26Z},
  url = {https://github.com/scikit-learn-contrib/imbalanced-learn},
  urldate = {2020-03-27},
  abstract = {A Python Package to Tackle the Curse of Imbalanced Datasets in Machine Learning},
  keywords = {data-analysis,data-science,machine-learning,python,statistics},
  organization = {{scikit-learn-contrib}}
}
% == BibLateX quality report for ScikitlearncontribImbalancedlearn2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@report{scottishgovernmentRedactingInformation2019,
  title = {Redacting {{Information}}},
  author = {{Scottish Government}},
  date = {2019-04},
  url = {https://www.gov.scot/binaries/content/documents/govscot/publications/foi-eir-release/2019/04/foi-19-00783/documents/foi-19-00783-information-released/foi-19-00783-information-released/govscot%3Adocument},
  urldate = {2020-02-16},
  file = {/home/architect/Zotero/storage/KS24FUXE/Scottish Government - 2019 - Redacting Information.pdf},
  number = {foi-19-00783}
}
% == BibLateX quality report for scottishgovernmentRedactingInformation2019:
% Missing required field 'type'
% Missing required field 'institution'
% ? Title looks like it was stored in title-case in Zotero

@video{ScottLundbergMicrosoft,
  title = {Scott {{Lundberg}}, {{Microsoft Research}} - {{Explainable Machine Learning}} with {{Shapley Values}} - \#{{H2OWorld}}},
  url = {https://www.youtube.com/watch?v=ngOBhhINWb8},
  urldate = {2020-01-20},
  abstract = {This session was recorded in NYC on October 22nd, 2019.

Slides from the session can be viewed here: https://www.slideshare.net/secret/MBL...

Explainable Machine Learning with Shapley Values

Shapley values are popular approach for explaining predictions made by complex machine learning models. In this talk I will discuss what problems Shapley values solve, an intuitive presentation of what they mean, and examples of how they can be used through the `shap' python package.

Bio: I am a senior researcher at Microsoft Research. Before joining Microsoft, I did my Ph.D. studies at the Paul G. Allen School of Computer Science \&amp; Engineering of the University of Washington working with Su-In Lee. My work focuses on explainable artificial intelligence and its application to problems in medicine and healthcare. This has led to the development of broadly applicable methods and tools for interpreting complex machine learning models that are now used in banking, logistics, sports, manufacturing, cloud services, economics, and many other areas.},
  keywords = {\#nosource}
}
% == BibLateX quality report for ScottLundbergMicrosoft:
% Unexpected field 'title'
% ? Title looks like it was stored in title-case in Zotero

@inproceedings{sferruzzaExtendingOpenAPIBuild2018,
  title = {Extending {{OpenAPI}} 3.0 to {{Build Web Services}} from Their {{Specification}}},
  booktitle = {International {{Conference}} on {{Web Information Systems}} and {{Technologies}}},
  author = {Sferruzza, David and Rocheteau, J\'er\^ome and Attiogb\'e, Christian and Lanoix, Arnaud},
  date = {2018-09},
  publisher = {{INSTICC}},
  location = {{Seville, Spain}},
  url = {https://hal.archives-ouvertes.fr/hal-01868498},
  urldate = {2020-03-16},
  abstract = {Web services are meant to be used by other programs. Developers (or other programs) need to understand how to interact with them, which means documentation is crucial. Some standards like OpenAPI define ways to document web services and target both humans and programs. Many tools can be used to help developers to work in a forward engineering process: they use hand-written OpenAPI models as input and automatically generate a skeleton of a working application, for example. However, this approach is not suitable to generate working applications if several evolutions occur over time, which often results in a misalignment between the OpenAPI model and the web services implementation. Here we show how we extend the OpenAPI 3.0 specification to allow building actual web services using a Model-Driven Engineering (MDE) approach. We extend the SWSG tool to make it possible to generate code from an extended OpenAPI model. This leverages a MDE approach to build web services from a model while benefiting from OpenAPI 3.0 tooling and ecosystem.},
  file = {/home/architect/Zotero/storage/AC94MJB2/Sferruzza et al. - 2018 - Extending OpenAPI 3.0 to Build Web Services from t.pdf},
  keywords = {Model-Driven Engineering,OpenAPI 30,Software Engineering,Web Applications,Web Services}
}
% == BibLateX quality report for sferruzzaExtendingOpenAPIBuild2018:
% ? Unsure about the formatting of the booktitle

@article{shapleyNotesNPersonGame1951,
  title = {Notes on the N-{{Person Game}}\textemdash{{II}}: {{The Value}} of an n-{{Person Game}}},
  author = {Shapley, Lloyd S.},
  date = {1951},
  publisher = {{Rand Corporation}},
  file = {/home/architect/Zotero/storage/G2MIRD92/RM670.pdf}
}
% == BibLateX quality report for shapleyNotesNPersonGame1951:
% Unexpected field 'publisher'
% Missing required field 'journaltitle'

@article{sloyanBorndigitalArchivesWellcome2016,
  title = {Born-Digital Archives at the {{Wellcome Library}}: Appraisal and Sensitivity Review of Two Hard Drives},
  shorttitle = {Born-Digital Archives at the {{Wellcome Library}}},
  author = {Sloyan, Victoria},
  date = {2016-01-02},
  journaltitle = {Archives and Records},
  shortjournal = {Arch. Rec.},
  volume = {37},
  pages = {20--36},
  issn = {2325-7962},
  doi = {10.1080/23257962.2016.1144504},
  abstract = {Digital preservation has been an ongoing issue for the archival profession for many years, with research primarily being focused on long-term preservation and user access. Attention is now turning to the important middle stage: processing born-digital archives, which encompasses several key tasks such as appraisal, arrangement, description and sensitivity review. The Wellcome Library is developing scalable workflows for born-digital archival processing that deal effectively both with hybrid and purely born-digital archives. These workflows are being devised and tested using two hard drives deposited within the archives of two genomic researchers, Ian Dunham and Michael Ashburner. This paper examines two specific and interconnected stages of archival processing: appraisal and sensitivity review. It sets out the Wellcome Library's approach to appraisal using a combination of several appraisal methods, namely functional, technical and `bottom-up' appraisal. It also demonstrates how tools such as DROID can be used to streamline the process. The paper then goes on to explore the Wellcome Library's risk management-based approach to the sensitivity review of born-digital material, suggesting there is a viable balance to be struck between closing large record series as a precaution and sensitivity reviewing at a very granular level.},
  file = {/home/architect/Zotero/storage/VVDQXN36/Sloyan - 2016 - Born-digital archives at the Wellcome Library app.pdf;/home/architect/Zotero/storage/WPTRP4B9/23257962.2016.html},
  keywords = {appraisal,archives,Born-digital,sensitivity review},
  number = {1}
}

@report{StateUKShale2016,
  title = {State of {{UK}} Shale Industry by 2020 and 2025 {{Main Report}} ({{Redacted}})},
  shorttitle = {State of {{UK}} Shale Industry by 2020 and 2025},
  date = {2016-04},
  pages = {48},
  institution = {{Cabinet Office}},
  url = {https://assets.documentcloud.org/documents/6563595/Cabinet-Office-fracking-report.pdf},
  urldate = {2020-01-04},
  abstract = {Based on a request from No10 Policy Unit, the Implementation Unit has reviewed the perspectives of industry and
others on the potential state of the UK shale industry by 2020.
Whilst it is known that the UK has significant shale reserves in the North of England (plus smaller reserves in the
South of England, Scotland and Wales), it has not yet been proven that their extraction is technically possible and
commercially viable. To date, three operators have submitted four planning applications for shale sites in the North of
England, none of which have received planning consent yet. Further operators are due to enter the industry in 2016 as
part of DECC's 14! Licensing Round, planning to bring forward potentially game-changing shale developments.
Given this context, this review has focused on four key questions:
What is the potential state of the UK shale industry in 2020?
\guillemotleft{} What are the key challenges and barriers to progress that industry faces in the run-up to 20207
*
How can the Government address these challenges and help accelerate industry progress?
What can we learn from the evolution of other shale markets (esp. US, CAN, ARG, POL) about the potential
development of the UK shale industry?},
  file = {/home/architect/Zotero/storage/TWEKH5A5/Cabinet-Office-fracking-report-fixed.pdf},
  langid = {english}
}
% == BibLateX quality report for StateUKShale2016:
% Missing required field 'author'
% Missing required field 'type'

@article{stoffelDocumentThumbnailsVariable2012,
  title = {Document {{Thumbnails}} with {{Variable Text Scaling}}},
  author = {Stoffel, A. and Strobelt, H. and Deussen, O. and Keim, D. A.},
  date = {2012},
  journaltitle = {Computer Graphics Forum},
  shortjournal = {Comput. Graph. Forum},
  volume = {31},
  pages = {1165--1173},
  issn = {1467-8659},
  doi = {10.1111/j.1467-8659.2012.03109.x},
  abstract = {Document reader applications usually offer an overview of the layout for each page as thumbnail views. Reading the text in these becomes impossible when the font size becomes very small. We improve the readability of these thumbnails using a distortion method, which retains a readable font size of interesting text while shrinking less interesting text further. In contrast to existing approaches, our method preserves the global layout of a page and is able to show context around important terms. We evaluate our technique and show application examples.},
  file = {/home/architect/Zotero/storage/Y4HPTVC8/Stoffel et al. - 2012 - Document Thumbnails with Variable Text Scaling.pdf;/home/architect/Zotero/storage/EVCFILAM/stoffel2012.html;/home/architect/Zotero/storage/WCNMKX6X/j.1467-8659.2012.03109.html},
  issue = {3pt3},
  langid = {english}
}
% == BibLateX quality report for stoffelDocumentThumbnailsVariable2012:
% ? Title looks like it was stored in title-case in Zotero

@article{strumbeljExplainingPredictionModels2014,
  title = {Explaining Prediction Models and Individual Predictions with Feature Contributions},
  author = {{\v S}trumbelj, Erik and Kononenko, Igor},
  date = {2014-12-01},
  journaltitle = {Knowledge and Information Systems},
  shortjournal = {Knowl Inf Syst},
  volume = {41},
  pages = {647--665},
  issn = {0219-3116},
  doi = {10.1007/s10115-013-0679-x},
  abstract = {We present a sensitivity analysis-based method for explaining prediction models that can be applied to any type of classification or regression model. Its advantage over existing general methods is that all subsets of input features are perturbed, so interactions and redundancies between features are taken into account. Furthermore, when explaining an additive model, the method is equivalent to commonly used additive model-specific methods. We illustrate the method's usefulness with examples from artificial and real-world data sets and an empirical analysis of running times. Results from a controlled experiment with 122 participants suggest that the method's explanations improved the participants' understanding of the model.},
  file = {/home/architect/Zotero/storage/A2XETQQ8/Å trumbelj and Kononenko - 2014 - Explaining prediction models and individual predic.pdf;/home/architect/Zotero/storage/AULXGLRT/10.1007@s10115-013-0679-x.html},
  langid = {english},
  number = {3}
}

@book{SYSTEMSSOFTWARESERVICES2019,
  title = {{{SYSTEMS}}, {{SOFTWARE AND SERVICES PROCESS IMPROVEMENT 26TH EUROPEAN}}.},
  date = {2019},
  publisher = {{SPRINGER NATURE}},
  location = {{S.l.}},
  file = {/home/architect/Zotero/storage/D6DVS92B/2019 - SYSTEMS, SOFTWARE AND SERVICES PROCESS IMPROVEMENT.pdf},
  isbn = {978-3-030-28004-8},
  langid = {english},
  note = {OCLC: 1107563133}
}
% == BibLateX quality report for SYSTEMSSOFTWARESERVICES2019:
% Missing required field 'author'
% ? Title looks like it was stored in title-case in Zotero

@software{Terrier2020,
  title = {Terrier},
  date = {2020-04-03T00:05:14Z},
  origdate = {2016-12-21T19:05:32Z},
  url = {https://github.com/terrier-org/terrier-core},
  urldate = {2020-04-06},
  abstract = {Terrier IR Platform. Contribute to terrier-org/terrier-core development by creating an account on GitHub.},
  keywords = {information-retrieval,java,terrier},
  organization = {{Terrier.org}}
}
% == BibLateX quality report for Terrier2020:
% Unexpected field 'title'
% Unexpected field 'organization'

@video{theinterceptSnowdenChomskyGreenwald2016,
  title = {Snowden, {{Chomsky}}, and {{Greenwald}} Discuss Privacy},
  editor = {{The Intercept}},
  date = {2016-03-30T17:18:59-04:00},
  url = {https://vimeo.com/160952562},
  urldate = {2020-04-04},
  abstract = {The balance between national security and government intrusion on the rights of private citizens was the topic of a panel discussion featuring renowned linguist\&hellip;},
  editortype = {director},
  file = {/home/architect/Zotero/storage/3R4HN4BC/160952562.html},
  keywords = {Edward Snowden,Glenn Greenwald,national security,Noam Chomsky,NSA,privacy,surveillance},
  langid = {english}
}
% == BibLateX quality report for theinterceptSnowdenChomskyGreenwald2016:
% Unexpected field 'title'
% Unexpected field 'editor'
% Unexpected field 'editortype'

@misc{thenationalarchivesRecordTransferReport2014,
  title = {Record {{Transfer Report}}: Monitoring and Reporting File Transfer to {{The National Archives}}, {{Spring}} 2014},
  shorttitle = {Record {{Transfer Report}}},
  author = {{The National Archives}},
  date = {2014},
  url = {http://www.nationalarchives.gov.uk/documents/record-transfer-report-spring-2014.xls},
  urldate = {2020-03-26},
  langid = {english}
}

@report{thenationalarchivesRedactionToolkitPaper2016,
  title = {Redaction Toolkit for Paper and Electronic Documents: {{Editing}} Exempt Information from Paper and Electronicdocuments Prior to Release},
  shorttitle = {Redaction Toolkit for Paper and Electronic Documents},
  author = {{The National Archives}},
  date = {2016-04},
  pages = {23},
  institution = {{The National Archives}},
  url = {https://www.nationalarchives.gov.uk/documents/information-management/redaction_toolkit.pdf},
  urldate = {2020-09-03},
  file = {/home/architect/Zotero/storage/XX6GUJPT/The National Archives - 2016 - Redaction toolkit for paper and electronic documen.pdf},
  langid = {english}
}
% == BibLateX quality report for thenationalarchivesRedactionToolkitPaper2016:
% Missing required field 'type'

@incollection{toughScopeAppetiteTechnologyassisted2018,
  title = {The Scope and Appetite for Technology-Assisted Sensitivity Reviewing of Born-Digital Records in a Resource Poor Environment: A Case Study from {{Malawi}}},
  shorttitle = {The Scope and Appetite for Technology-Assisted Sensitivity Reviewing of Born-Digital Records in a Resource Poor Environment},
  booktitle = {Handbook of {{Research}} on {{Heritage Management}} and {{Preservation}}},
  author = {Tough, Alistair},
  editor = {Ngulube, Patrick},
  date = {2018-02},
  pages = {175--182},
  publisher = {{IGI Global}},
  url = {https://www.igi-global.com/book/handbook-research-heritage-management-preservation/179828},
  urldate = {2020-02-16},
  abstract = {Concerns about sensitive content in born-digital records seem to be a major factor in inhibiting the deposit
of public records in dedicated digital repositories in Western countries. These concerns are much
exacerbated by the changed nature of the process of reviewing records. The University of Glasgow,
working in collaboration with the Foreign and Commonwealth Office, received funding to investigate the
technology-assisted sensitivity reviewing of born-digital records. As part of this research, some preliminary
research in a commonwealth country in Sub-Saharan Africa was carried out. The research, reported in
this chapter, was carried out in Malawi by the late Dr. Mathews J. Phiri. He found that already there
is a real, albeit limited, demand for technology-assisted sensitivity reviewing of born-digital records in
Malawi. The available evidence suggests that within the next decade there is likely to be an increase in
the need for effective means of assessing sensitivity in born-digital records.},
  file = {/home/architect/Zotero/storage/9KSY9IWE/150844.html},
  isbn = {978-1-5225-3137-1},
  langid = {english}
}

@book{turnbullDockerBookContainerization2014,
  title = {The {{Docker Book}}: {{Containerization Is}} the {{New Virtualization}}},
  shorttitle = {The {{Docker Book}}},
  author = {Turnbull, James},
  date = {2014-07-14},
  publisher = {{James Turnbull}},
  abstract = {Updated for Docker Community Edition v18.09!Docker book designed for SysAdmins, SREs, Operations staff, Developers and DevOps who are interested in deploying the open source container service Docker.~In this book, we\&\#39;ll walk you through installing, deploying, managing, and extending Docker. We\&\#39;re going to do that by first introducing you to the basics of Docker and its components. Then we\&\#39;ll start to use Docker to build containers and services to perform a variety of tasks.~We\&\#39;re going to take you through the development lifecycle, from testing to production, and see where Docker fits in and how it can make your life easier. We\&\#39;ll make use of Docker to build test environments for new projects, demonstrate how to integrate Docker with continuous integration workflow, and then how to build application services and platforms. Finally, we\&\#39;ll show you how to use Docker\&\#39;s API and how to extend Docker yourself.~We\&\#39;ll teach you how to:~* Install Docker.~* Take your first steps with a Docker container.~* Build Docker images.~* Manage and share Docker images.~* Run and manage more complex Docker containers.~* Deploy Docker containers as part of your testing pipeline.~* Build multi-container applications and environments. * Learn about orchestration using Compose and Swarm for the orchestration of Docker containers and Consul for service discovery.* Explore the Docker API. * Getting Help and Extending Docker.},
  eprint = {4xQKBAAAQBAJ},
  eprinttype = {googlebooks},
  isbn = {978-0-9888202-0-3},
  keywords = {Computers / General,Technology & Engineering / General},
  langid = {english},
  pagetotal = {398}
}
% == BibLateX quality report for turnbullDockerBookContainerization2014:
% ? Title looks like it was stored in title-case in Zotero

@software{tyurinAgentcooperReactpdfhighlighter2020,
  title = {Agentcooper/React-Pdf-Highlighter},
  author = {Tyurin, Artem},
  date = {2020-04-03T23:41:47Z},
  origdate = {2017-11-25T19:36:50Z},
  url = {https://github.com/agentcooper/react-pdf-highlighter},
  urldate = {2020-04-04},
  abstract = {Set of React components for PDF annotation. Contribute to agentcooper/react-pdf-highlighter development by creating an account on GitHub.},
  keywords = {annotator,highlighting,pdf,pdf-viewer,react}
}
% == BibLateX quality report for tyurinAgentcooperReactpdfhighlighter2020:
% Unexpected field 'title'
% Unexpected field 'author'
% ? Title looks like it was stored in lower-case in Zotero

@video{UnifiedApproachInterpreting,
  title = {A {{Unified Approach}} to {{Interpreting Model Predictions}} - {{NIPS}} 2017},
  url = {https://www.youtube.com/watch?v=wjd1G5bu_TY},
  urldate = {2020-01-20},
  abstract = {NIPS 2017 Short},
  keywords = {\#nosource}
}
% == BibLateX quality report for UnifiedApproachInterpreting:
% Unexpected field 'title'
% ? Title looks like it was stored in title-case in Zotero

@software{VuejsVue2020,
  title = {Vuejs/Vue},
  date = {2020},
  origdate = {2013-07-29T03:24:51Z},
  url = {https://github.com/vuejs/vue},
  urldate = {2020-03-20},
  abstract = {ðŸ–– Vue.js is a progressive, incrementally-adoptable JavaScript framework for building UI on the web.},
  keywords = {framework,frontend,javascript,vue},
  organization = {{vuejs}}
}
% == BibLateX quality report for VuejsVue2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@book{walkerSystemsSoftwareServices2019,
  title = {Systems, {{Software}} and {{Services Process Improvement}}: 26th {{European Conference}}, {{EuroSPI}} 2019, {{Edinburgh}}, {{UK}}, {{September}} 18\textendash{}20, 2019, {{Proceedings}}},
  shorttitle = {Systems, {{Software}} and {{Services Process Improvement}}},
  author = {Walker, Alastair and O'Connor, Rory V. and Messnarz, Richard},
  date = {2019-10-12},
  publisher = {{Springer Nature}},
  abstract = {This volume constitutes the refereed proceedings of the 26th European Conference on Systems, Software and Services Process Improvement, EuroSPI conference, held in Edinburgh, Scotland, in September 2019. The 18 revised full papers presented were carefully reviewed and selected from 28 submissions. They are organized in topical sections: Visionary Papers, SPI and Safety and Security, SPI and Assessments, SPI and Future Qualification \& Team Performance, and SPI Manifesto and Culture. The selected workshop papers are also presented and organized in following topical sections: GamifySPI, Digitalisation of Industry, Infrastructure and E-Mobility. -Best Practices in Implementing Traceability. -Good and Bad Practices in Improvement. -Functional Safety and Cybersecurity. -Experiences with Agile and Lean. -Standards and Assessment Models. -Team Skills and Diversity Strategies. -Recent Innovations.},
  eprint = {v0yuDwAAQBAJ},
  eprinttype = {googlebooks},
  file = {/home/architect/Zotero/storage/5CWHE57C/Walker et al. - 2019 - Systems, Software and Services Process Improvement.pdf},
  isbn = {978-3-030-28005-5},
  keywords = {Business & Economics / Information Management,Computers / General,Computers / Hardware / Mobile Devices,Computers / Information Technology,Computers / Intelligence (AI) & Semantics,Computers / Software Development & Engineering / General,Computers / Software Development & Engineering / Systems Analysis & Design,Computers / System Administration / Storage & Retrieval,Computers / Systems Architecture / General},
  langid = {english},
  pagetotal = {770}
}
% == BibLateX quality report for walkerSystemsSoftwareServices2019:
% ? Title looks like it was stored in title-case in Zotero

@article{wenThunderSVMFastSVM2018,
  ids = {wenThunderSVMFastSVM2018a},
  title = {{{ThunderSVM}}: A Fast {{SVM}} Library on {{GPUs}} and {{CPUs}}},
  shorttitle = {{{ThunderSVM}}},
  author = {Wen, Zeyi and Shi, Jiashuai and Li, Qinbin and He, Bingsheng and Chen, Jian},
  date = {2018-01-01},
  journaltitle = {The Journal of Machine Learning Research},
  shortjournal = {J. Mach. Learn. Res.},
  volume = {19},
  pages = {797--801},
  issn = {1532-4435},
  abstract = {Support Vector Machines (SVMs) are classic supervised learning models for classification, regression and distribution estimation. A survey conducted by Kaggle in 2017 shows that 26\% of the data mining and machine learning practitioners are users of SVMs. However, SVM training and prediction are very expensive computationally for large and complex problems. This paper presents an efficient and open source SVM software toolkit called ThunderSVM which exploits the high-performance of Graphics Processing Units (GPUs) and multi-core CPUs. ThunderSVM supports all the functionalities--including classification (SVC), regression (SVR) and one-class SVMs--of LibSVM and uses identical command line options, such that existing LibSVM users can easily apply our toolkit. ThunderSVM can be used through multiple language interfaces including C/C++, Python, R and MATLAB. Our experimental results show that ThunderSVM is generally an order of magnitude faster than LibSVM while producing identical SVMs. In addition to the high efficiency, we design our convex optimization solver in a general way such that SVC, SVR, and one-class SVMs share the same solver for the ease of maintenance. Documentation, examples, and more about ThunderSVM are available at https://github.com/zeyiwen/thundersvm.},
  file = {/home/architect/Zotero/storage/2S8C7WPQ/Wen et al. - 2018 - ThunderSVM a fast SVM library on GPUs and CPUs.pdf;/home/architect/Zotero/storage/RJTUIE2U/Wen et al. - 2018 - ThunderSVM a fast SVM library on GPUs and CPUs.pdf},
  keywords = {efficiency,GPUs,multi-core CPUs,multiple interfaces,No DOI found,SVMs},
  number = {1}
}

@online{WhyDevelopersFlask,
  title = {Why Developers like {{Flask}}},
  date = {2020},
  journaltitle = {StackShare},
  url = {https://stackshare.io/flask},
  urldate = {2020-03-20},
  abstract = {See what developers are saying about how they use Flask. Check out popular companies that use Flask and some tools that integrate with Flask.},
  file = {/home/architect/Zotero/storage/XKRNL5QE/flask.html},
  langid = {english},
  note = {Library Catalog: stackshare.io}
}
% == BibLateX quality report for WhyDevelopersFlask:
% Unexpected field 'journaltitle'

@thesis{wohlgethanSupportingWebDevelopmentDecisions2018,
  title = {{{SupportingWeb Development Decisions}} by {{Comparing Three Major JavaScript Frameworks}}: {{Angular}}, {{React}} and {{Vue}}. Js},
  author = {Wohlgethan, Eric},
  date = {2018},
  institution = {{Hochschule f\"ur Angewandte Wissenschaften Hamburg}},
  file = {/home/architect/Zotero/storage/TUQXICSZ/Wohlgethan - Entscheidungshilfe fÃ¼r die Webentwicklung anhand d.pdf},
  langid = {english},
  pagetotal = {84}
}
% == BibLateX quality report for wohlgethanSupportingWebDevelopmentDecisions2018:
% Missing required field 'type'

@software{ZalandoConnexion2020,
  title = {Zalando/Connexion},
  date = {2020-03-20T09:37:22Z},
  origdate = {2015-05-19T13:05:58Z},
  url = {https://github.com/zalando/connexion},
  urldate = {2020-03-20},
  abstract = {Swagger/OpenAPI First framework for Python on top of Flask with automatic endpoint validation \& OAuth2 support},
  keywords = {api-rest,flask-extensions,microservices,openapi,python,swagger,web},
  organization = {{Zalando SE}}
}
% == BibLateX quality report for ZalandoConnexion2020:
% Unexpected field 'title'
% Unexpected field 'organization'
% ? Title looks like it was stored in lower-case in Zotero

@software{zhongVincentdchanReactfisheye2019,
  title = {Vincentdchan/React-Fisheye},
  author = {Zhong},
  date = {2019-11-18T12:36:51Z},
  origdate = {2019-08-31T11:12:18Z},
  url = {https://github.com/vincentdchan/react-fisheye},
  urldate = {2019-12-10},
  abstract = {React-fisheye is a react component implements fisheye effect.},
  keywords = {\#nosource,component,effects,react}
}
% == BibLateX quality report for zhongVincentdchanReactfisheye2019:
% Unexpected field 'title'
% Unexpected field 'author'
% ? Title looks like it was stored in lower-case in Zotero


